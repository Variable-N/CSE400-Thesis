{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1KXrRMh5GqlyiGc1GnPUrXQUP3vh8pXiD","timestamp":1682962787026}],"mount_file_id":"1rKKM4PPG4tdFYABm6bEleGDfk0SQMZHg","authorship_tag":"ABX9TyMe9TI/gFjwUNL0xOd9pfq2"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["#Imports\n"],"metadata":{"id":"Rzie1jIrWWaj"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_OuUlYg-Vqr3","executionInfo":{"status":"ok","timestamp":1682962904673,"user_tz":-360,"elapsed":76279,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"9c7484d8-2d41-447c-8e6e-fdd880afd4c8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/csebuetnlp/normalizer\n","  Cloning https://github.com/csebuetnlp/normalizer to /tmp/pip-req-build-2rq6o3b0\n","  Running command git clone --filter=blob:none --quiet https://github.com/csebuetnlp/normalizer /tmp/pip-req-build-2rq6o3b0\n","  Resolved https://github.com/csebuetnlp/normalizer to commit d80c3c484e1b80268f2b2dfaf7557fe65e34f321\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from normalizer==0.0.1) (2022.10.31)\n","Collecting emoji==1.4.2 (from normalizer==0.0.1)\n","  Downloading emoji-1.4.2.tar.gz (184 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.0/185.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting ftfy==6.0.3 (from normalizer==0.0.1)\n","  Downloading ftfy-6.0.3.tar.gz (64 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy==6.0.3->normalizer==0.0.1) (0.2.6)\n","Building wheels for collected packages: normalizer, emoji, ftfy\n","  Building wheel for normalizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for normalizer: filename=normalizer-0.0.1-py3-none-any.whl size=6877 sha256=c9734987a0df7e2e5429da027d45345131e67c8d6d948c4f5a790686c81ddb8f\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-66yuaezi/wheels/2e/79/9c/cd96d490298305d51d2da11484bb2c25fd1f759a6906708282\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-1.4.2-py3-none-any.whl size=186471 sha256=074063c3fa3c6bf74e3b71f31dc8efc7d8b5e2dd8c40f28762a5d9515a95f829\n","  Stored in directory: /root/.cache/pip/wheels/10/f0/fd/4813b1177405693e8da9cdea839f0fb64fde161380e058c827\n","  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=e830b86f6640a03917079063941991d715413ada989925730bb15b8ce07a7b1a\n","  Stored in directory: /root/.cache/pip/wheels/92/8e/16/c1e4d4d65685d71085e4e27b44d6ed880b0559474c9ee4ff66\n","Successfully built normalizer emoji ftfy\n","Installing collected packages: emoji, ftfy, normalizer\n","Successfully installed emoji-1.4.2 ftfy-6.0.3 normalizer-0.0.1\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install git+https://github.com/csebuetnlp/normalizer\n","!pip install datasets -q\n","!pip install tokenizers -q\n","!pip install transformers -q\n","!pip install seqeval -q"]},{"cell_type":"code","source":["from normalizer import normalize\n","import torch\n","from transformers import ElectraTokenizer, ElectraForPreTraining, ElectraForTokenClassification, AdamW\n","from transformers import pipeline, AutoTokenizer, AutoModelForPreTraining , BertModel\n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","import pickle"],"metadata":{"id":"X4CkHyVcWde7","executionInfo":{"status":"ok","timestamp":1682962917520,"user_tz":-360,"elapsed":12855,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm"],"metadata":{"id":"tH-pVs7yXQE0","executionInfo":{"status":"ok","timestamp":1682962917521,"user_tz":-360,"elapsed":13,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["#Gazeteer import"],"metadata":{"id":"2727jgNSWglC"}},{"cell_type":"code","source":["class TrieNode:\n","    def __init__(self):\n","        self.children = {}\n","        self.is_end_of_word = False\n","\n","class Trie:\n","    def __init__(self):\n","        self.root = TrieNode()\n","        self.entity_tags = [\"PER\", \"LOC\", \"CW\", \"CORP\", \"GRP\", \"PROD\"]\n","        self.tag_encoding = {\"O\": 0, \"B-PER\": 1, \"I-PER\": 2, \"B-LOC\": 3, \"I-LOC\": 4,\n","                             \"B-CW\": 5, \"I-CW\": 6, \"B-CORP\": 7, \"I-CORP\": 8, \n","                             \"B-GRP\": 9, \"I-GRP\": 10, \"B-PROD\": 11, \"I-PROD\": 12}\n","\n","    def insert(self, word, entity_type):\n","        node = self.root\n","        for char in word:\n","            if char not in node.children:\n","                node.children[char] = TrieNode()\n","            node = node.children[char]\n","        node.is_end_of_word = True\n","        node.entity_type = entity_type\n","\n","    def search(self, sentence):\n","        encoding = [0] * len(sentence)\n","        for i in range(len(sentence)):\n","            node = self.root\n","            for j in range(i, len(sentence)):\n","                char = sentence[j]\n","                if char not in node.children:\n","                    break\n","                node = node.children[char]\n","                if node.is_end_of_word:\n","                    entity_type = node.entity_type\n","                    entity_length = j - i + 1\n","                    start_index = i\n","                    end_index = j\n","                    for k in range(start_index, end_index + 1):\n","                        if k == start_index:\n","                            encoding[k] = self.tag_encoding[\"B-\" + entity_type]\n","                        else:\n","                            encoding[k] = self.tag_encoding[\"I-\" + entity_type]\n","                    break\n","        one_hot_encoding = [[0] * 13 for i in range(len(encoding))]\n","        for i, tag in enumerate(encoding):\n","            one_hot_encoding[i][tag] = 1\n","        return one_hot_encoding\n","\n","import numpy as np\n","\n","def group_encodings_by_word(encoding, sentence):\n","    # Create an empty list to store the word encodings\n","    word_encodings = []\n","    \n","    # Create an empty list to store the current word encoding\n","    current_word_encoding = []\n","    \n","    # Create an empty string to store the current word\n","    current_word = \"\"\n","    \n","    # Iterate over each character encoding and character in the input encoding list and sentence, respectively\n","    for char_encoding, char in zip(encoding, sentence):\n","        # If the current character is a whitespace character, finish the current word and add its first character encoding to the word encodings list\n","        if char == \" \":\n","            if len(current_word_encoding) > 0:\n","                word_encodings.append(np.array(current_word_encoding[0]))\n","                current_word_encoding = []\n","            current_word = \"\"\n","        # If the current character is part of a word, append the character encoding to the current word encoding and the character to the current word\n","        else:\n","            current_word_encoding.append(char_encoding)\n","            current_word += char\n","    \n","    # Add the last word encoding to the word encodings list, if it exists\n","    if len(current_word_encoding) > 0:\n","        word_encodings.append(np.array(current_word_encoding[0]))\n","    \n","    # Return the word encodings as a NumPy array\n","    return torch.from_numpy(np.array(word_encodings)).type(torch.float32)\n","\n","\n","\n","def save_trie(trie, filename):\n","    with open(filename, \"wb\") as f:\n","        pickle.dump(trie, f)\n","\n","def load_trie(filename):\n","    with open(filename, \"rb\") as f:\n","        trie = pickle.load(f)\n","    return trie\n"],"metadata":{"id":"dNCs1HzcWiOr","executionInfo":{"status":"ok","timestamp":1682962917523,"user_tz":-360,"elapsed":12,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def Gtoken(text):\n","  inputs = tokenizer.encode_plus(text, return_tensors='pt')\n","\n","  encoded_dict = tokenizer.encode_plus(\n","                  text,       # Sentence to encode.\n","                  add_special_tokens = False, # Add '[CLS]' and '[SEP]'\n","                  max_length = 314,           # Pad & truncate all sentences.\n","                  padding = 'max_length',\n","                  return_attention_mask = True,   # Construct attn. masks.\n","                  return_tensors = 'pt',\n","                  truncation=False)\n","  input_ids = encoded_dict['input_ids']\n","  tokenized = tokenizer.convert_ids_to_tokens([i.item() for i in input_ids.squeeze() if i > 1])\n","  return \"< \"+\" \".join(tokenized)+\" >\""],"metadata":{"id":"Ke73PhsfWmpm","executionInfo":{"status":"ok","timestamp":1682962917524,"user_tz":-360,"elapsed":12,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Bracu/THESIS/Trie DS/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cv17GrxKWuUa","executionInfo":{"status":"ok","timestamp":1682962966126,"user_tz":-360,"elapsed":1312,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"9f59df15-fb75-4e98-c1a6-d4cf96df5fc8"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Bracu/THESIS/Trie DS\n"]}]},{"cell_type":"code","source":["trie = load_trie('Trie.bin')"],"metadata":{"id":"Q-0m6FdiWw5w","executionInfo":{"status":"ok","timestamp":1682962974119,"user_tz":-360,"elapsed":5478,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["model_name = '/content/drive/MyDrive/Thesis/BERTOUTPUT/checkpoint-11000/'\n","tokenizer = ElectraTokenizer.from_pretrained(model_name)"],"metadata":{"id":"PWhUQqBxWzbu","executionInfo":{"status":"ok","timestamp":1682962978500,"user_tz":-360,"elapsed":4385,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["def pad_tensor(tensor):\n","    current_size = tensor.size(0)\n","    if current_size >= 64:\n","        return tensor[:64, :]  # if the tensor is larger than (64, 13), truncate it\n","    \n","    padded_tensor = torch.zeros((64, 13))\n","    padded_tensor[:current_size, :] = tensor  # copy the input tensor to the padded tensor\n","    return padded_tensor\n","\n"],"metadata":{"id":"UYanpwBTf4Fc","executionInfo":{"status":"ok","timestamp":1682962978501,"user_tz":-360,"elapsed":8,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["def Gazetteer(sentence, pad = True):\n","  sentence = Gtoken(normalize(sentence))\n","  encoding = trie.search(sentence)\n","  tensor = group_encodings_by_word(encoding,sentence)\n","  if pad:\n","    current_size = tensor.size(0)\n","    if current_size >= 64:\n","        return tensor[:64, :]  # if the tensor is larger than (64, 13), truncate it\n","    \n","    padded_tensor = torch.zeros((64, 13))\n","    padded_tensor[:current_size, :] = tensor  # copy the input tensor to the padded tensor\n","    return padded_tensor\n","  else: \n","    return tensor"],"metadata":{"id":"aa-Q7PsdW2jL","executionInfo":{"status":"ok","timestamp":1682962982140,"user_tz":-360,"elapsed":3,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["Gazetteer(\"২০১৮ এর সেরা বর্ণানুক্রমিকভাবে তালিকাভুক্ত র‍্যাঙ্ক করা হয়নি এনপিআর\").size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6zgXT8hFW29E","executionInfo":{"status":"ok","timestamp":1682963645042,"user_tz":-360,"elapsed":6,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"7dc1297c-5ecf-468e-90c9-4dce281752bd"},"execution_count":32,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([64, 13])"]},"metadata":{},"execution_count":32}]},{"cell_type":"markdown","source":["#Dataset Load"],"metadata":{"id":"O1Eea7a3XN7z"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Bracu/THESIS/DatasetSir"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wqUNaMpXXHkO","executionInfo":{"status":"ok","timestamp":1682962990499,"user_tz":-360,"elapsed":3,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"5aee03bd-42de-4739-872b-da4b9c2c6c7b"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Bracu/THESIS/DatasetSir\n"]}]},{"cell_type":"code","source":["# Load the NER dataset\n","df_train = pd.read_csv('trainData2022PP2.csv')\n","df_val = pd.read_csv('devData2022PP2.csv')\n","df_test = pd.read_csv('testData2022PP2.csv')"],"metadata":{"id":"3L8OdYN3XRDS","executionInfo":{"status":"ok","timestamp":1682962994190,"user_tz":-360,"elapsed":3108,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":16,"outputs":[]},{"cell_type":"code","source":["d = {'O': 0, 'B-CORP': 1, 'I-CORP': 2, 'B-CW': 3, 'I-CW': 4, 'B-GRP': 5, 'I-GRP': 6, 'B-LOC': 7, 'I-LOC': 8, 'B-PER': 9, 'I-PER': 10, 'B-PROD': 11, 'I-PROD': 12}\n","def label_encoder(x):\n","    x = eval(x)\n","    y = []\n","    for i in x:\n","      y.append(d[i])\n","    return y\n","\n","def text_normalizer(x):\n","    return normalize(x)\n","\n","df_train['Word'] = df_train['Word'].apply(lambda x: text_normalizer(x))\n","df_test['Word'] = df_test['Word'].apply(lambda x: text_normalizer(x))\n","df_val['Word'] = df_val['Word'].apply(lambda x: text_normalizer(x))\n","df_train['Tag'] = df_train['Tag'].apply(lambda x: label_encoder(x))\n","df_test['Tag'] = df_test['Tag'].apply(lambda x: label_encoder(x))\n","df_val['Tag'] = df_val['Tag'].apply(lambda x: label_encoder(x))\n","df_train.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"mUFCsyUPXTDS","executionInfo":{"status":"ok","timestamp":1682963029380,"user_tz":-360,"elapsed":30878,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"dfe08dde-0a92-46df-d454-674badc3843f"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        Sentence #                                               Word  \\\n","0      Sentence: 1  ২০১৮ এর সেরা বর্ণানুক্রমিকভাবে তালিকাভুক্ত র‍্...   \n","1     Sentence: 10   সিনেমায় গানটির বৈশিষ্ট্য রয়েছে রাস্তা যাত্রা ।   \n","2    Sentence: 100  করে বাদ্যযন্ত্রের থিম এবং চলচ্চিত্রের জন্য প্র...   \n","3   Sentence: 1000  প্রতিষ্ঠান ২২১১ ইঙ্গিত করে যে আউগুস্তুস পৃথক ক...   \n","4  Sentence: 10000  শো স্টপারে তাদের বেকড আলাস্কা করতে সাড়ে চার ঘ...   \n","\n","                                          Tag  \n","0                 [0, 0, 0, 0, 0, 0, 0, 0, 1]  \n","1                       [0, 0, 0, 0, 3, 4, 0]  \n","2                    [5, 0, 0, 0, 0, 0, 0, 0]  \n","3  [0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0]  \n","4         [0, 0, 0, 11, 12, 0, 0, 0, 0, 0, 0]  "],"text/html":["\n","  <div id=\"df-eb432cfc-2a95-4ee6-8151-4676b0880796\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence #</th>\n","      <th>Word</th>\n","      <th>Tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sentence: 1</td>\n","      <td>২০১৮ এর সেরা বর্ণানুক্রমিকভাবে তালিকাভুক্ত র‍্...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sentence: 10</td>\n","      <td>সিনেমায় গানটির বৈশিষ্ট্য রয়েছে রাস্তা যাত্রা ।</td>\n","      <td>[0, 0, 0, 0, 3, 4, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sentence: 100</td>\n","      <td>করে বাদ্যযন্ত্রের থিম এবং চলচ্চিত্রের জন্য প্র...</td>\n","      <td>[5, 0, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sentence: 1000</td>\n","      <td>প্রতিষ্ঠান ২২১১ ইঙ্গিত করে যে আউগুস্তুস পৃথক ক...</td>\n","      <td>[0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sentence: 10000</td>\n","      <td>শো স্টপারে তাদের বেকড আলাস্কা করতে সাড়ে চার ঘ...</td>\n","      <td>[0, 0, 0, 11, 12, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-eb432cfc-2a95-4ee6-8151-4676b0880796')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-eb432cfc-2a95-4ee6-8151-4676b0880796 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-eb432cfc-2a95-4ee6-8151-4676b0880796');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["def one_hot_encode_list(lst, pad = True):\n","    \"\"\"\n","    One-hot encodes each element in a Python list and returns a tensor containing the one-hot encodings.\n","    \n","    Args:\n","    - lst: A Python list\n","    \n","    Returns:\n","    - A PyTorch tensor with shape (len(lst), 13), where each row represents the one-hot encoding of an element in the input list.\n","    \"\"\"\n","    one_hot_tensors = torch.zeros(len(lst), 13)\n","    for i, elem in enumerate(lst):\n","        one_hot = torch.zeros(13)\n","        one_hot[elem] = 1\n","        one_hot_tensors[i] = one_hot\n","    if pad:\n","      tensor = one_hot_tensors\n","      current_size = tensor.size(0)\n","      if current_size >= 64:\n","          return tensor[:64, :]  # if the tensor is larger than (64, 13), truncate it\n","      \n","      padded_tensor = torch.zeros((64, 13))\n","      padded_tensor[:current_size, :] = tensor  # copy the input tensor to the padded tensor\n","      return padded_tensor\n","\n","\n","one_hot_encode_list([0, 0, 0, 0, 3, 4, 0]).size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yTP7H0A5-0of","executionInfo":{"status":"ok","timestamp":1682963034682,"user_tz":-360,"elapsed":5,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"00ab1e62-93bd-4f37-c538-d1a94be9d919"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([64, 13])"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["def tokenized_df(text):\n","    inputs = tokenizer(text, max_length = 64, padding = 'max_length', return_tensors='pt')\n","    input_ids = inputs['input_ids']\n","    return input_ids\n","\n","def tokenized_df1(text):\n","    inputs = tokenizer(text, max_length = 64, padding = 'max_length', return_tensors='pt')\n","    attention_mask = inputs['attention_mask']\n","    return attention_mask\n","def tokenized_df2(text):\n","    gazetteer = Gazetteer(text).unsqueeze(0)\n","    return gazetteer"],"metadata":{"id":"B1UgpyqfXVLu","executionInfo":{"status":"ok","timestamp":1682963037973,"user_tz":-360,"elapsed":2,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["df_val['input_ids'] =  df_val['Word'].apply(lambda x: tokenized_df(x))\n","df_val['attention_mask'] =  df_val['Word'].apply(lambda x: tokenized_df1(x))\n","df_val['gazetteer'] =  df_val['Word'].apply(lambda x: tokenized_df2(x))\n","df_train['input_ids'] = df_train['Word'].apply(lambda x: tokenized_df(x))\n","df_train['attention_mask'] = df_train['Word'].apply(lambda x: tokenized_df1(x))\n","df_train['gazetteer'] = df_train['Word'].apply(lambda x: tokenized_df2(x))"],"metadata":{"id":"9hePzPudX_Q4","executionInfo":{"status":"ok","timestamp":1682963128620,"user_tz":-360,"elapsed":88596,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["df_val['Tag'] =  df_val['Tag'].apply(lambda x: one_hot_encode_list(x))\n","df_train['Tag'] =  df_train['Tag'].apply(lambda x: one_hot_encode_list(x))"],"metadata":{"id":"4dZQtGunAKP8","executionInfo":{"status":"ok","timestamp":1682963135140,"user_tz":-360,"elapsed":4556,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":21,"outputs":[]},{"cell_type":"code","source":["df_train.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":528},"id":"c3uYaweVAYj_","executionInfo":{"status":"ok","timestamp":1682963138828,"user_tz":-360,"elapsed":3703,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"bb1e8aa3-de81-4f0f-f2d6-94d2258408fd"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        Sentence #                                               Word  \\\n","0      Sentence: 1  ২০১৮ এর সেরা বর্ণানুক্রমিকভাবে তালিকাভুক্ত র‍্...   \n","1     Sentence: 10   সিনেমায় গানটির বৈশিষ্ট্য রয়েছে রাস্তা যাত্রা ।   \n","2    Sentence: 100  করে বাদ্যযন্ত্রের থিম এবং চলচ্চিত্রের জন্য প্র...   \n","3   Sentence: 1000  প্রতিষ্ঠান ২২১১ ইঙ্গিত করে যে আউগুস্তুস পৃথক ক...   \n","4  Sentence: 10000  শো স্টপারে তাদের বেকড আলাস্কা করতে সাড়ে চার ঘ...   \n","\n","                                                 Tag  \\\n","0  [[tensor(1.), tensor(0.), tensor(0.), tensor(0...   \n","1  [[tensor(1.), tensor(0.), tensor(0.), tensor(0...   \n","2  [[tensor(0.), tensor(0.), tensor(0.), tensor(0...   \n","3  [[tensor(1.), tensor(0.), tensor(0.), tensor(0...   \n","4  [[tensor(1.), tensor(0.), tensor(0.), tensor(0...   \n","\n","                                           input_ids  \\\n","0  [[tensor(2), tensor(7349), tensor(919), tensor...   \n","1  [[tensor(2), tensor(13509), tensor(20928), ten...   \n","2  [[tensor(2), tensor(792), tensor(31661), tenso...   \n","3  [[tensor(2), tensor(2857), tensor(3312), tenso...   \n","4  [[tensor(2), tensor(3057), tensor(22353), tens...   \n","\n","                                      attention_mask  \\\n","0  [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n","1  [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n","2  [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n","3  [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n","4  [[tensor(1), tensor(1), tensor(1), tensor(1), ...   \n","\n","                                           gazetteer  \n","0  [[[tensor(1.), tensor(0.), tensor(0.), tensor(...  \n","1  [[[tensor(1.), tensor(0.), tensor(0.), tensor(...  \n","2  [[[tensor(1.), tensor(0.), tensor(0.), tensor(...  \n","3  [[[tensor(1.), tensor(0.), tensor(0.), tensor(...  \n","4  [[[tensor(1.), tensor(0.), tensor(0.), tensor(...  "],"text/html":["\n","  <div id=\"df-3b98ef56-2248-46af-8e72-f6e5a8b998e2\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence #</th>\n","      <th>Word</th>\n","      <th>Tag</th>\n","      <th>input_ids</th>\n","      <th>attention_mask</th>\n","      <th>gazetteer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sentence: 1</td>\n","      <td>২০১৮ এর সেরা বর্ণানুক্রমিকভাবে তালিকাভুক্ত র‍্...</td>\n","      <td>[[tensor(1.), tensor(0.), tensor(0.), tensor(0...</td>\n","      <td>[[tensor(2), tensor(7349), tensor(919), tensor...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","      <td>[[[tensor(1.), tensor(0.), tensor(0.), tensor(...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sentence: 10</td>\n","      <td>সিনেমায় গানটির বৈশিষ্ট্য রয়েছে রাস্তা যাত্রা ।</td>\n","      <td>[[tensor(1.), tensor(0.), tensor(0.), tensor(0...</td>\n","      <td>[[tensor(2), tensor(13509), tensor(20928), ten...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","      <td>[[[tensor(1.), tensor(0.), tensor(0.), tensor(...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sentence: 100</td>\n","      <td>করে বাদ্যযন্ত্রের থিম এবং চলচ্চিত্রের জন্য প্র...</td>\n","      <td>[[tensor(0.), tensor(0.), tensor(0.), tensor(0...</td>\n","      <td>[[tensor(2), tensor(792), tensor(31661), tenso...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","      <td>[[[tensor(1.), tensor(0.), tensor(0.), tensor(...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sentence: 1000</td>\n","      <td>প্রতিষ্ঠান ২২১১ ইঙ্গিত করে যে আউগুস্তুস পৃথক ক...</td>\n","      <td>[[tensor(1.), tensor(0.), tensor(0.), tensor(0...</td>\n","      <td>[[tensor(2), tensor(2857), tensor(3312), tenso...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","      <td>[[[tensor(1.), tensor(0.), tensor(0.), tensor(...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sentence: 10000</td>\n","      <td>শো স্টপারে তাদের বেকড আলাস্কা করতে সাড়ে চার ঘ...</td>\n","      <td>[[tensor(1.), tensor(0.), tensor(0.), tensor(0...</td>\n","      <td>[[tensor(2), tensor(3057), tensor(22353), tens...</td>\n","      <td>[[tensor(1), tensor(1), tensor(1), tensor(1), ...</td>\n","      <td>[[[tensor(1.), tensor(0.), tensor(0.), tensor(...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3b98ef56-2248-46af-8e72-f6e5a8b998e2')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3b98ef56-2248-46af-8e72-f6e5a8b998e2 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3b98ef56-2248-46af-8e72-f6e5a8b998e2');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","source":["#Model"],"metadata":{"id":"Pk4JvLo0YzcB"}},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TkuLIchdYz_Z","executionInfo":{"status":"ok","timestamp":1682963175135,"user_tz":-360,"elapsed":712,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"ad4108cd-b1fd-4f1a-b325-8ee85d2de125"},"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cpu')"]},"metadata":{},"execution_count":23}]},{"cell_type":"code","source":["bert = ElectraForTokenClassification.from_pretrained(model_name, output_hidden_states=True)"],"metadata":{"id":"Wdjbyt3PNXc-","executionInfo":{"status":"ok","timestamp":1682963293731,"user_tz":-360,"elapsed":45922,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"qU0DRbhFZ9vW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text1 = \"সিনেমায় গানটির বৈশিষ্ট্য রয়েছে রাস্তা যাত্রা ।\"\n","text2 = \"সিনেমায় গানটির বৈশিষ্ট্য\"\n","inputs1 = tokenizer(text1, max_length = 64, padding = 'max_length', return_tensors='pt')\n","inputs2 = tokenizer(text1, max_length = 64, padding = 'max_length', return_tensors='pt')"],"metadata":{"id":"b1VYoDZNNZ2k"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text = [\"সিনেমায় গানটির বৈশিষ্ট্য রয়েছে রাস্তা যাত্রা ।\", \"সিনেমায় গানটির বৈশিষ্ট্য\"]\n","inputs = tokenizer(text, max_length = 64, padding = 'max_length', return_tensors='pt')"],"metadata":{"id":"96yvGXw0TJ7p","executionInfo":{"status":"ok","timestamp":1682966107520,"user_tz":-360,"elapsed":705,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":81,"outputs":[]},{"cell_type":"code","source":["inputs['input_ids'].size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vs3Q6pJdS-FQ","executionInfo":{"status":"ok","timestamp":1682966111462,"user_tz":-360,"elapsed":6,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"16141075-c531-42a0-f902-4f53daf9a19f"},"execution_count":82,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 64])"]},"metadata":{},"execution_count":82}]},{"cell_type":"code","source":["x = bert(inputs['input_ids'], inputs['attention_mask'])"],"metadata":{"id":"M5WWmiemNaN2","executionInfo":{"status":"ok","timestamp":1682966114520,"user_tz":-360,"elapsed":2403,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":83,"outputs":[]},{"cell_type":"code","source":["x[0].size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xT03JSyvNaLn","executionInfo":{"status":"ok","timestamp":1682966114520,"user_tz":-360,"elapsed":5,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"3c00c63a-9608-4d4e-db9a-26b82d27ea51"},"execution_count":84,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 64, 13])"]},"metadata":{},"execution_count":84}]},{"cell_type":"code","source":["hidden_states = x.hidden_states\n","layer6 = hidden_states[6]\n","layer12 = hidden_states[12]\n","layer18 = hidden_states[18]\n","\n","\n","torch.mean(torch.stack([layer6, layer12, layer18]), dim=0).size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HBPcbu5MkSoP","executionInfo":{"status":"ok","timestamp":1682966451324,"user_tz":-360,"elapsed":1194,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"ed8d1fd8-eccd-49e5-818f-e2dc27897ee2"},"execution_count":90,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([2, 64, 1024])"]},"metadata":{},"execution_count":90}]},{"cell_type":"code","source":["x"],"metadata":{"id":"JYhMWMJckk0H"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class NERClassification(nn.Module):\n","  def __init__(self, n_classes):\n","    super(NERClassification, self).__init__()\n","    self.bert = ElectraForTokenClassification.from_pretrained(model_name, output_hidden_states=True)\n","    self.drop = nn.Dropout(p=0.1)\n","    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n","    self.gOut = nn.Linear(n_classes,n_classes)\n","    self.final_out = nn.Linear(2*n_classes, n_classes)\n","    self.softmax = nn.Softmax(dim = 1)\n","\n","  def forward(self, input_ids, attention_mask, gazetteer):\n","    pooled_output = self.bert(\n","      input_ids=input_ids,\n","      attention_mask=attention_mask\n","    )\n","\n","    hidden_states = pooled_output.hidden_states\n","\n","    # print(hidden_states)\n","    \n","    layer6 = hidden_states[6]\n","    layer12 = hidden_states[12]\n","    layer18 = hidden_states[18]\n","\n","\n","    averaged_hidden_states = torch.mean(torch.stack([layer6, layer12, layer18]), dim=0)\n","\n","    # print(pooled_output)\n","\n","    output = self.drop(averaged_hidden_states)\n","    output = self.out(output)\n","    goutput = self.gOut(gazetteer)\n","    final_output = torch.concat((output,goutput), dim = 2)\n","    final_output = self.final_out(final_output)\n","    final_output = self.softmax(final_output)\n","    return final_output"],"metadata":{"id":"a_mLbA0yY6dn","executionInfo":{"status":"ok","timestamp":1682966755243,"user_tz":-360,"elapsed":996,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":93,"outputs":[]},{"cell_type":"code","source":["model = NERClassification(n_classes=13)"],"metadata":{"id":"k7rTLJZ-Y9mG","executionInfo":{"status":"ok","timestamp":1682966771505,"user_tz":-360,"elapsed":14303,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":94,"outputs":[]},{"cell_type":"code","source":["from torchsummary import summary\n","summary(model, [(2, 64), (2, 64), (2,64,13)])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":328},"id":"juwDOdO4cIoF","executionInfo":{"status":"error","timestamp":1682966656105,"user_tz":-360,"elapsed":7,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"ae6a2008-e0d5-415b-d9f5-5c7d8038f8e7"},"execution_count":92,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-92-300a44ebe948>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchsummary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msummary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchsummary/torchsummary.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(model, input_size, batch_size, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# make a forward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;31m# print(x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;31m# remove these hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: NERClassification.forward() missing 1 required positional argument: 'gazetteer'"]}]},{"cell_type":"code","source":["text = \"সিনেমায় গানটির বৈশিষ্ট্য রয়েছে রাস্তা যাত্রা ।\"\n","inputs = tokenizer(text, max_length = 64, padding = 'max_length', return_tensors='pt')\n"],"metadata":{"id":"bn64hkOsZCM2","executionInfo":{"status":"ok","timestamp":1682972400274,"user_tz":-360,"elapsed":518,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":105,"outputs":[]},{"cell_type":"code","source":["inputs['input_ids']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5fvHIUGrZDbc","executionInfo":{"status":"ok","timestamp":1682944483504,"user_tz":-360,"elapsed":6,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"7d618009-2a59-4fe3-decf-4b92939f75cf"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[    2, 13509, 20928,  7887,  1401,  2772,  5078,   205,     3,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0],\n","        [    2, 13509, 20928,  7887,     3,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0]])"]},"metadata":{},"execution_count":39}]},{"cell_type":"code","source":["inputs['attention_mask'].size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F_VPyClSbQN8","executionInfo":{"status":"ok","timestamp":1682938618602,"user_tz":-360,"elapsed":12,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"3e4c3605-3613-42cf-9eee-c1106c2d50d5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 64])"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["Gazetteer(text)[0][0]"],"metadata":{"id":"ufb5PVS8aeq_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682972437352,"user_tz":-360,"elapsed":3,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"6357703d-9154-4bf1-dfed-87d33b29f225"},"execution_count":107,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(1.)"]},"metadata":{},"execution_count":107}]},{"cell_type":"code","source":["torch.full((64, 13),-100.)[0][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XrdXZ1FD-b6j","executionInfo":{"status":"ok","timestamp":1682972489975,"user_tz":-360,"elapsed":2,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"e7c7859e-04ef-4694-dd49-a47c9336d4e3"},"execution_count":110,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor(-100.)"]},"metadata":{},"execution_count":110}]},{"cell_type":"code","source":["inputs['input_ids'].to(device).size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SRlmyX1te7i_","executionInfo":{"status":"ok","timestamp":1682964209311,"user_tz":-360,"elapsed":522,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"896b4839-625f-4b12-94d8-af3142016b90"},"execution_count":52,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 64])"]},"metadata":{},"execution_count":52}]},{"cell_type":"code","source":["inputs['attention_mask'].to(device).size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"XJn8I6uje-vx","executionInfo":{"status":"ok","timestamp":1682964223130,"user_tz":-360,"elapsed":4,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"a56818f5-439a-4c26-8e2a-b25b1e1de350"},"execution_count":53,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 64])"]},"metadata":{},"execution_count":53}]},{"cell_type":"code","source":["\n","\n","text = \"সিনেমায় গানটির বৈশিষ্ট্য রয়েছে রাস্তা যাত্রা ।\"\n","inputs = tokenizer(text, max_length = 64, padding = 'max_length', return_tensors='pt')\n","\n","input_ids = inputs['input_ids'].to(device)\n","attention_mask = inputs['attention_mask'].to(device)\n","gazetteer = Gazetteer(text).unsqueeze(0).to(device)\n","# Run the model\n","outputs = model(input_ids=input_ids, attention_mask=attention_mask, gazetteer = gazetteer)\n","\n","print(outputs.size())\n","\n","# Get the predicted label\n","x, predicted_label = torch.max(outputs, dim=2)\n","\n","predicted_label\n","\n","# Print the predicted label\n","# print(predicted_label.item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T1llOGuWY_gz","executionInfo":{"status":"ok","timestamp":1682966774499,"user_tz":-360,"elapsed":3016,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"4fe51f26-b0df-4f0e-e07b-3a9620812589"},"execution_count":95,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 64, 13])\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[ 9,  9,  6,  9,  0,  9,  3,  9,  9,  2,  5, 11,  8,  6,  0, 10,  5,  1,\n","          5,  4, 10,  4,  0,  2, 12,  0,  2,  4,  2,  4,  4,  0, 10,  4,  3,  2,\n","         11,  5,  8,  6, 10,  5,  1,  7,  6,  2,  1,  8,  0, 11,  0,  1, 10,  2,\n","          4, 11,  1,  0, 10, 10, 11,  7,  8,  8]])"]},"metadata":{},"execution_count":95}]},{"cell_type":"code","source":["torch.tensor([[[]]])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fTAaN19TuyJV","executionInfo":{"status":"ok","timestamp":1682969996698,"user_tz":-360,"elapsed":6,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"ebc57f63-ec42-43a7-daad-f1ae0e8ff5a0"},"execution_count":103,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([], size=(1, 1, 0))"]},"metadata":{},"execution_count":103}]},{"cell_type":"code","source":["#Multiple\n","\n","text = [\"সিনেমায় গানটির বৈশিষ্ট্য রয়েছে রাস্তা যাত্রা ।\", \"সিনেমায় গানটির বৈশিষ্ট্য\"]\n","inputs = tokenizer(text, max_length = 64, padding = 'max_length', return_tensors='pt')\n","\n","input_ids = inputs['input_ids'].to(device)\n","attention_mask = inputs['attention_mask'].to(device)\n","gazetteer1 = Gazetteer(text[0]).unsqueeze(0).to(device)\n","gazetteer2 =  Gazetteer(text[1]).unsqueeze(0).to(device)\n","gazetteer = torch.cat((gazetteer1,gazetteer2),0)\n","# Run the model\n","outputs = model(input_ids=input_ids, attention_mask=attention_mask, gazetteer = gazetteer)\n","\n","print(outputs.size())\n","\n","# Get the predicted label\n","x, predicted_label = torch.max(outputs, dim=2)\n","\n","predicted_label\n","\n","# Print the predicted label\n","# print(predicted_label.item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HoJkoQkroycD","executionInfo":{"status":"ok","timestamp":1682967002955,"user_tz":-360,"elapsed":2713,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"ffb3025a-ff5e-48b4-ac27-265ce32d65e9"},"execution_count":96,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([2, 64, 13])\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[ 9,  9, 12,  6,  0,  9,  3,  9,  6,  4,  8,  8,  8,  9,  0, 10,  5, 12,\n","         11,  6,  4,  5,  0,  3,  5,  1,  7,  5,  2,  7,  7,  0, 10,  5,  1, 11,\n","          8,  5,  7,  1,  5,  5,  0, 11,  8, 10,  6,  5,  0,  0,  7, 10,  7,  1,\n","          4,  4,  1,  0,  8, 10,  9,  1, 11, 10],\n","        [ 9,  9,  4,  9,  6,  4,  0,  0,  9,  2,  2,  8,  5,  6,  2,  0,  2,  2,\n","          5, 12,  8,  8,  8,  1,  3,  1,  4, 12,  0, 10,  4,  7,  0,  4,  0,  5,\n","         10, 11,  7,  1,  1, 11,  0,  0,  7,  1,  8,  1,  8,  1,  7,  7, 12,  8,\n","          8, 10,  8,  8,  7,  7,  2,  7,  5, 10]])"]},"metadata":{},"execution_count":96}]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","from transformers import AdamW\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","model.to(device)\n","model.train()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iza7_6PPgi1C","executionInfo":{"status":"ok","timestamp":1682961916210,"user_tz":-360,"elapsed":8545,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"69166bbf-cb95-432a-ba22-b13d83d3f775"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["NERClassification(\n","  (bert): ElectraForTokenClassification(\n","    (electra): ElectraModel(\n","      (embeddings): ElectraEmbeddings(\n","        (word_embeddings): Embedding(32000, 1024, padding_idx=0)\n","        (position_embeddings): Embedding(512, 1024)\n","        (token_type_embeddings): Embedding(2, 1024)\n","        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): ElectraEncoder(\n","        (layer): ModuleList(\n","          (0-23): 24 x ElectraLayer(\n","            (attention): ElectraAttention(\n","              (self): ElectraSelfAttention(\n","                (query): Linear(in_features=1024, out_features=1024, bias=True)\n","                (key): Linear(in_features=1024, out_features=1024, bias=True)\n","                (value): Linear(in_features=1024, out_features=1024, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): ElectraSelfOutput(\n","                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): ElectraIntermediate(\n","              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): ElectraOutput(\n","              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (classifier): Linear(in_features=1024, out_features=13, bias=True)\n","  )\n","  (drop): Dropout(p=0.1, inplace=False)\n","  (out): Linear(in_features=1024, out_features=13, bias=True)\n","  (gOut): Linear(in_features=13, out_features=13, bias=True)\n","  (final_out): Linear(in_features=26, out_features=13, bias=True)\n","  (softmax): Softmax(dim=1)\n",")"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["df_train['input_ids'][0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"mROey7aJmAyZ","executionInfo":{"status":"ok","timestamp":1682961916210,"user_tz":-360,"elapsed":11,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"849bc474-6fcd-4b29-cea3-f6174f5e1d9c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[    2,  7349,   919,  3577, 26501, 11126, 12900,  5319, 15785, 16053,\n","           913,  1702,  2594,  1353,  3173,     3,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n","             0,     0,     0,     0]])"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["df_train.shape[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"12vrbohhCBBl","executionInfo":{"status":"ok","timestamp":1682961916211,"user_tz":-360,"elapsed":8,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"513976f2-918d-49cd-f36b-f1c3f5cff121"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["15301"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["from torch.nn import BCELoss\n","\n","loss1 = BCELoss()\n","optim = AdamW(model.parameters(), lr=5e-5)\n","\n","for epoch in range(3):\n","    for j in tqdm(range(df_train.shape[0])):\n","        optim.zero_grad()\n","        i,a,g, label = df_train['input_ids'][j].to(device) , df_train['attention_mask'][j].to(device) ,df_train['gazetteer'][j].to(device) ,df_train['Tag'][j].unsqueeze(0).to(device)\n","        outputs = model(input_ids = i, attention_mask=a, gazetteer = g)\n","        loss = loss1(outputs,label)\n","        if j % 100 == 0:\n","          print(loss)\n","        loss.backward()\n","        optim.step()\n","\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RmQUjXNqWSB-","outputId":"0e8029be-76ff-4eea-f81e-2044ef087378"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","  0%|          | 1/15301 [00:00<34:25,  7.41it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0388, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 102/15301 [00:14<33:23,  7.59it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0334, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["  1%|▏         | 202/15301 [00:31<37:25,  6.73it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0407, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 301/15301 [00:45<40:16,  6.21it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0347, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["  3%|▎         | 401/15301 [00:58<37:47,  6.57it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0953, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["  3%|▎         | 501/15301 [01:12<36:45,  6.71it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0211, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["  4%|▍         | 601/15301 [01:25<35:29,  6.90it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0730, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["  5%|▍         | 702/15301 [01:40<31:48,  7.65it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0384, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["  5%|▌         | 801/15301 [01:56<33:48,  7.15it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0612, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["  6%|▌         | 902/15301 [02:10<31:54,  7.52it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.1020, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["  7%|▋         | 1002/15301 [02:23<31:10,  7.64it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0309, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["  7%|▋         | 1102/15301 [02:37<30:41,  7.71it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0977, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["  8%|▊         | 1202/15301 [02:51<30:46,  7.64it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0254, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["  9%|▊         | 1302/15301 [03:05<30:27,  7.66it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0872, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["  9%|▉         | 1402/15301 [03:19<30:20,  7.64it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0385, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 10%|▉         | 1502/15301 [03:33<30:18,  7.59it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0433, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 10%|█         | 1602/15301 [03:46<30:54,  7.39it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0608, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 11%|█         | 1701/15301 [04:00<35:51,  6.32it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0454, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 12%|█▏        | 1801/15301 [04:14<33:22,  6.74it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0317, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 12%|█▏        | 1888/15301 [04:26<28:56,  7.72it/s]"]}]},{"cell_type":"code","source":["class NERDataset(Dataset):\n","  def __init__(self,df):\n","    self.input_ids = df['input_ids']\n","    self.attention_mask = df['attention_mask']\n","    self.gazetteer = df['gazetteer']\n","    self.label = df['Tag']\n","    self.n_samples = df.shape[0]\n","\n","  def __getitem__(self, idx):\n","    return self.input_ids[idx].to(device),self.attention_mask[idx].to(device),self.gazetteer[idx].to(device),self.label[idx].to(device)\n","  \n","  def __len__(self):\n","    return self.n_samples\n","    "],"metadata":{"id":"PNTHTC5wkUr6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = NERDataset(df_train)"],"metadata":{"id":"nKWSNb5dDYT0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset.n_samples"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EkfJmNh3FE4r","executionInfo":{"status":"ok","timestamp":1682940844360,"user_tz":-360,"elapsed":5,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"8d0d3270-2e05-403f-d9f0-fbafa20fb7b2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["15301"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":[],"metadata":{"id":"e6LpN9LYWQsw"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_loader = DataLoader(dataset = train_dataset, batch_size=1, shuffle=True)"],"metadata":{"id":"mdkocqalE5Zj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.nn import BCELoss\n","\n","loss = BCELoss()\n","optim = AdamW(model.parameters(), lr=5e-5)\n","\n","for epoch in range(3):\n","    for batch in train_loader:\n","        optim.zero_grad()\n","        i,a,g, label = batch\n","        outputs = model(input_ids = i, attention_mask=a, gazetteer = g)\n","        loss = loss(outputs,label)\n","        loss.backward()\n","        optim.step()\n","\n","model.eval()"],"metadata":{"id":"V6hg1Qb7WOCL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.nn import CrossEntropyLoss\n","\n","loss1 = CrossEntropyLoss()\n","optim = AdamW(model.parameters(), lr=5e-5)\n","\n","batch = 32\n","for i in tqdm(range(df_train.shape[0]//batch)):\n","  text = []\n","  g = None\n","  for t in tqdm(range(batch*i, (batch*i)+batch)):\n","    optim.zero_grad()\n","    df_train['Tag'][j].unsqueeze(0).to(device)\n","    text.append(df_train['Word'][t])\n","    if t == batch*i:\n","      g = Gazetteer(df_train['Word'][t]).unsqueeze(0).to(device)\n","    else:\n","      g = torch.cat((g,Gazetteer(df_train['Word'][t]).unsqueeze(0).to(device)),0)\n","\n","\n","\n","  inputs = tokenizer(text, max_length = 64, padding = 'max_length', return_tensors='pt')\n","  inp = inputs['input_ids'].to(device)\n","  a = inputs['attention_mask'].to(device)\n","  label = df_train['Tag'][j].unsqueeze(0).to(device)\n","  outputs = model(input_ids = inp, attention_mask=a, gazetteer = g)\n","  loss = loss1(outputs,label)\n","  if j % 100 == 0:\n","    print(loss)\n","  loss.backward()\n","  optim.step()\n","\n","model.eval()\n","\n"],"metadata":{"id":"NU-pYMlhs6wh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.nn import CrossEntropyLoss\n","\n","loss1 = CrossEntropyLoss()\n","optim = AdamW(model.parameters(), lr=5e-5)\n","\n","for epoch in range(3):\n","    for j in tqdm(range(df_train.shape[0]//32)):\n","        optim.zero_grad()\n","        \n","        i,a,g, label = df_train['input_ids'][j].to(device) , df_train['attention_mask'][j].to(device) ,df_train['gazetteer'][j].to(device) ,df_train['Tag'][j].unsqueeze(0).to(device)\n","        outputs = model(input_ids = i, attention_mask=a, gazetteer = g)\n","        loss = loss1(outputs,label)\n","        if j % 100 == 0:\n","          print(loss)\n","        loss.backward()\n","        optim.step()\n","\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":415},"id":"vIJCwJBOf_zZ","executionInfo":{"status":"error","timestamp":1682941528089,"user_tz":-360,"elapsed":29,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"c5d60578-3098-4312-c6a2-ba7b0e45781a"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-70-91d188b86d6b>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgazetteer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-67-18b5c1b245cf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, gazetteer)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgazetteer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     pooled_output,_ = self.bert(\n\u001b[0m\u001b[1;32m     13\u001b[0m       \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1298\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m         discriminator_hidden_states = self.electra(\n\u001b[0m\u001b[1;32m   1301\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You have to specify either input_ids or inputs_embeds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"]}]},{"cell_type":"code","source":[],"metadata":{"id":"CjCW00V3hAiL"},"execution_count":null,"outputs":[]}]}