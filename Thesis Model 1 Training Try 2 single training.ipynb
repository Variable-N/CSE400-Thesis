{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1KXrRMh5GqlyiGc1GnPUrXQUP3vh8pXiD","timestamp":1683398306255}],"mount_file_id":"1OCPQXThcECuExjAK6rPHKEDqcCH_6H1i","authorship_tag":"ABX9TyPsKfoCJIPRXMWQijyXvoDR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["#Imports\n"],"metadata":{"id":"Rzie1jIrWWaj"}},{"cell_type":"code","source":["!pip install torchmetrics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"KIpzKvEP12UE","executionInfo":{"status":"ok","timestamp":1683406432927,"user_tz":-360,"elapsed":10503,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"6503d129-f3f2-4829-c75b-d391615bee18"},"execution_count":127,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting torchmetrics\n","  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (1.22.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (23.1)\n","Requirement already satisfied: torch>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from torchmetrics) (2.0.0+cu118)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (1.11.1)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (2.0.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.12.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (3.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.1->torchmetrics) (4.5.0)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (16.0.2)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.8.1->torchmetrics) (3.25.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.8.1->torchmetrics) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.1->torchmetrics) (1.3.0)\n","Installing collected packages: torchmetrics\n","Successfully installed torchmetrics-0.11.4\n"]}]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_OuUlYg-Vqr3","executionInfo":{"status":"ok","timestamp":1683398403552,"user_tz":-360,"elapsed":47991,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"f597a90b-d910-4cb4-e6f7-768774f4ea2e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/csebuetnlp/normalizer\n","  Cloning https://github.com/csebuetnlp/normalizer to /tmp/pip-req-build-ol0yh9ql\n","  Running command git clone --filter=blob:none --quiet https://github.com/csebuetnlp/normalizer /tmp/pip-req-build-ol0yh9ql\n","  Resolved https://github.com/csebuetnlp/normalizer to commit d80c3c484e1b80268f2b2dfaf7557fe65e34f321\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from normalizer==0.0.1) (2022.10.31)\n","Collecting emoji==1.4.2\n","  Downloading emoji-1.4.2.tar.gz (184 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.0/185.0 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting ftfy==6.0.3\n","  Downloading ftfy-6.0.3.tar.gz (64 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from ftfy==6.0.3->normalizer==0.0.1) (0.2.6)\n","Building wheels for collected packages: normalizer, emoji, ftfy\n","  Building wheel for normalizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for normalizer: filename=normalizer-0.0.1-py3-none-any.whl size=6877 sha256=584487d9733ac0df0162a93ef96bde1a52377ec94c71e45679035b263c88cc1b\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-2f90zo0k/wheels/2e/79/9c/cd96d490298305d51d2da11484bb2c25fd1f759a6906708282\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-1.4.2-py3-none-any.whl size=186471 sha256=9bfccf65f2f47e2d4a2c02166304c5cc5b656c1d3b1b4947b9d8dca9eeb70b96\n","  Stored in directory: /root/.cache/pip/wheels/10/f0/fd/4813b1177405693e8da9cdea839f0fb64fde161380e058c827\n","  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=03c20081b4d3abddea405e49d045a241bf0ace651c8d927b52094c89efc91d36\n","  Stored in directory: /root/.cache/pip/wheels/92/8e/16/c1e4d4d65685d71085e4e27b44d6ed880b0559474c9ee4ff66\n","Successfully built normalizer emoji ftfy\n","Installing collected packages: emoji, ftfy, normalizer\n","Successfully installed emoji-1.4.2 ftfy-6.0.3 normalizer-0.0.1\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m474.6/474.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.5/212.5 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.3/134.3 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m59.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install git+https://github.com/csebuetnlp/normalizer\n","!pip install datasets -q\n","!pip install tokenizers -q\n","!pip install transformers -q\n","!pip install seqeval -q"]},{"cell_type":"code","source":["from normalizer import normalize\n","import torch\n","from transformers import ElectraTokenizer, ElectraForPreTraining, ElectraForTokenClassification, AdamW\n","from transformers import pipeline, AutoTokenizer, AutoModelForPreTraining , BertModel\n","from torch import nn\n","from torch.utils.data import Dataset, DataLoader\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","import pickle"],"metadata":{"id":"X4CkHyVcWde7","executionInfo":{"status":"ok","timestamp":1683398416701,"user_tz":-360,"elapsed":13156,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["from tqdm import tqdm"],"metadata":{"id":"tH-pVs7yXQE0","executionInfo":{"status":"ok","timestamp":1683398416702,"user_tz":-360,"elapsed":18,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["#Gazeteer import"],"metadata":{"id":"2727jgNSWglC"}},{"cell_type":"code","source":["class TrieNode:\n","    def __init__(self):\n","        self.children = {}\n","        self.is_end_of_word = False\n","\n","class Trie:\n","    def __init__(self):\n","        self.root = TrieNode()\n","        self.entity_tags = [\"PER\", \"LOC\", \"CW\", \"CORP\", \"GRP\", \"PROD\"]\n","        self.tag_encoding = {\"O\": 0, \"B-PER\": 1, \"I-PER\": 2, \"B-LOC\": 3, \"I-LOC\": 4,\n","                             \"B-CW\": 5, \"I-CW\": 6, \"B-CORP\": 7, \"I-CORP\": 8, \n","                             \"B-GRP\": 9, \"I-GRP\": 10, \"B-PROD\": 11, \"I-PROD\": 12}\n","\n","    def insert(self, word, entity_type):\n","        node = self.root\n","        for char in word:\n","            if char not in node.children:\n","                node.children[char] = TrieNode()\n","            node = node.children[char]\n","        node.is_end_of_word = True\n","        node.entity_type = entity_type\n","\n","    def search(self, sentence):\n","        encoding = [0] * len(sentence)\n","        for i in range(len(sentence)):\n","            node = self.root\n","            for j in range(i, len(sentence)):\n","                char = sentence[j]\n","                if char not in node.children:\n","                    break\n","                node = node.children[char]\n","                if node.is_end_of_word:\n","                    entity_type = node.entity_type\n","                    entity_length = j - i + 1\n","                    start_index = i\n","                    end_index = j\n","                    for k in range(start_index, end_index + 1):\n","                        if k == start_index:\n","                            encoding[k] = self.tag_encoding[\"B-\" + entity_type]\n","                        else:\n","                            encoding[k] = self.tag_encoding[\"I-\" + entity_type]\n","                    break\n","        one_hot_encoding = [[0] * 13 for i in range(len(encoding))]\n","        for i, tag in enumerate(encoding):\n","            one_hot_encoding[i][tag] = 1\n","        return one_hot_encoding\n","\n","import numpy as np\n","\n","def group_encodings_by_word(encoding, sentence):\n","    # Create an empty list to store the word encodings\n","    word_encodings = []\n","    \n","    # Create an empty list to store the current word encoding\n","    current_word_encoding = []\n","    \n","    # Create an empty string to store the current word\n","    current_word = \"\"\n","    \n","    # Iterate over each character encoding and character in the input encoding list and sentence, respectively\n","    for char_encoding, char in zip(encoding, sentence):\n","        # If the current character is a whitespace character, finish the current word and add its first character encoding to the word encodings list\n","        if char == \" \":\n","            if len(current_word_encoding) > 0:\n","                word_encodings.append(np.array(current_word_encoding[0]))\n","                current_word_encoding = []\n","            current_word = \"\"\n","        # If the current character is part of a word, append the character encoding to the current word encoding and the character to the current word\n","        else:\n","            current_word_encoding.append(char_encoding)\n","            current_word += char\n","    \n","    # Add the last word encoding to the word encodings list, if it exists\n","    if len(current_word_encoding) > 0:\n","        word_encodings.append(np.array(current_word_encoding[0]))\n","    \n","    # Return the word encodings as a NumPy array\n","    return torch.from_numpy(np.array(word_encodings)).type(torch.float32)\n","\n","\n","\n","def save_trie(trie, filename):\n","    with open(filename, \"wb\") as f:\n","        pickle.dump(trie, f)\n","\n","def load_trie(filename):\n","    with open(filename, \"rb\") as f:\n","        trie = pickle.load(f)\n","    return trie\n"],"metadata":{"id":"dNCs1HzcWiOr","executionInfo":{"status":"ok","timestamp":1683398416702,"user_tz":-360,"elapsed":16,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["def Gtoken(text):\n","  inputs = tokenizer.encode_plus(text, return_tensors='pt')\n","\n","  encoded_dict = tokenizer.encode_plus(\n","                  text,       # Sentence to encode.\n","                  add_special_tokens = False, # Add '[CLS]' and '[SEP]'\n","                  max_length = 314,           # Pad & truncate all sentences.\n","                  padding = 'max_length',\n","                  return_attention_mask = True,   # Construct attn. masks.\n","                  return_tensors = 'pt',\n","                  truncation=False)\n","  input_ids = encoded_dict['input_ids']\n","  tokenized = tokenizer.convert_ids_to_tokens([i.item() for i in input_ids.squeeze() if i > 1])\n","  return \"< \"+\" \".join(tokenized)+\" >\""],"metadata":{"id":"Ke73PhsfWmpm","executionInfo":{"status":"ok","timestamp":1683398416702,"user_tz":-360,"elapsed":15,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Bracu/THESIS/Trie DS/"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Cv17GrxKWuUa","executionInfo":{"status":"ok","timestamp":1683398416703,"user_tz":-360,"elapsed":16,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"5d51cf15-9c9d-4384-a282-e8eb24fa5d5b"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Bracu/THESIS/Trie DS\n"]}]},{"cell_type":"code","source":["trie = load_trie('Trie final.bin')"],"metadata":{"id":"Q-0m6FdiWw5w","executionInfo":{"status":"ok","timestamp":1683398452710,"user_tz":-360,"elapsed":15752,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["model_name = '/content/drive/MyDrive/Thesis/BERTOUTPUT/checkpoint-11000/'\n","tokenizer = ElectraTokenizer.from_pretrained(model_name)"],"metadata":{"id":"PWhUQqBxWzbu","executionInfo":{"status":"ok","timestamp":1683398454540,"user_tz":-360,"elapsed":1859,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["def pad_tensor(tensor):\n","    current_size = tensor.size(0)\n","    if current_size >= 64:\n","        return tensor[:64, :]  # if the tensor is larger than (64, 13), truncate it\n","    \n","    padded_tensor = torch.zeros((64, 13))\n","    padded_tensor[:current_size, :] = tensor  # copy the input tensor to the padded tensor\n","    return padded_tensor\n","\n"],"metadata":{"id":"UYanpwBTf4Fc","executionInfo":{"status":"ok","timestamp":1683398466581,"user_tz":-360,"elapsed":1,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["def Gazetteer(sentence, pad = False):\n","  sentence = Gtoken(normalize(sentence))\n","  encoding = trie.search(sentence)\n","  tensor = group_encodings_by_word(encoding,sentence)\n","  if pad:\n","    current_size = tensor.size(0)\n","    if current_size >= 64:\n","        return tensor[:64, :]  # if the tensor is larger than (64, 13), truncate it\n","    \n","    padded_tensor = torch.zeros((64, 13))\n","    padded_tensor[:current_size, :] = tensor  # copy the input tensor to the padded tensor\n","    return padded_tensor\n","  else: \n","    return tensor"],"metadata":{"id":"aa-Q7PsdW2jL","executionInfo":{"status":"ok","timestamp":1683398564305,"user_tz":-360,"elapsed":7,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":19,"outputs":[]},{"cell_type":"code","source":["Gazetteer(\"২০১৮ এর সেরা বর্ণানুক্রমিকভাবে তালিকাভুক্ত র‍্যাঙ্ক করা হয়নি এনপিআর\", False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6zgXT8hFW29E","executionInfo":{"status":"ok","timestamp":1683398474172,"user_tz":-360,"elapsed":2,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"8721157f-5fe9-4a3e-cbdb-1c5e03f18115"},"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"]},"metadata":{},"execution_count":11}]},{"cell_type":"markdown","source":["#Dataset Load"],"metadata":{"id":"O1Eea7a3XN7z"}},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Bracu/THESIS/DatasetSir"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wqUNaMpXXHkO","executionInfo":{"status":"ok","timestamp":1683398480314,"user_tz":-360,"elapsed":558,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"53ae0966-4ce4-40bd-c401-a9d10076ef83"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Bracu/THESIS/DatasetSir\n"]}]},{"cell_type":"code","source":["# Load the NER dataset\n","df_train = pd.read_csv('trainData2022PP2.csv')\n","df_val = pd.read_csv('devData2022PP2.csv')\n","df_test = pd.read_csv('testData2022PP2.csv')"],"metadata":{"id":"3L8OdYN3XRDS","executionInfo":{"status":"ok","timestamp":1683399558836,"user_tz":-360,"elapsed":1539,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":49,"outputs":[]},{"cell_type":"code","source":["d = {'O': 0, 'B-CORP': 1, 'I-CORP': 2, 'B-CW': 3, 'I-CW': 4, 'B-GRP': 5, 'I-GRP': 6, 'B-LOC': 7, 'I-LOC': 8, 'B-PER': 9, 'I-PER': 10, 'B-PROD': 11, 'I-PROD': 12}\n","def label_encoder(x):\n","    x = eval(x)\n","    y = []\n","    for i in x:\n","      y.append(d[i])\n","    return y\n","\n","def text_normalizer(x):\n","    return normalize(x)\n","\n","df_train['Word'] = df_train['Word'].apply(lambda x: text_normalizer(x))\n","df_test['Word'] = df_test['Word'].apply(lambda x: text_normalizer(x))\n","df_val['Word'] = df_val['Word'].apply(lambda x: text_normalizer(x))\n","df_train['Tag'] = df_train['Tag'].apply(lambda x: label_encoder(x))\n","df_test['Tag'] = df_test['Tag'].apply(lambda x: label_encoder(x))\n","df_val['Tag'] = df_val['Tag'].apply(lambda x: label_encoder(x))\n","df_train.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"mUFCsyUPXTDS","executionInfo":{"status":"ok","timestamp":1683399579492,"user_tz":-360,"elapsed":19358,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"5fe6c112-6bb8-45d1-f0a9-c311c6d23918"},"execution_count":50,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        Sentence #                                               Word  \\\n","0      Sentence: 1  ২০১৮ এর সেরা বর্ণানুক্রমিকভাবে তালিকাভুক্ত র‍্...   \n","1     Sentence: 10   সিনেমায় গানটির বৈশিষ্ট্য রয়েছে রাস্তা যাত্রা ।   \n","2    Sentence: 100  করে বাদ্যযন্ত্রের থিম এবং চলচ্চিত্রের জন্য প্র...   \n","3   Sentence: 1000  প্রতিষ্ঠান ২২১১ ইঙ্গিত করে যে আউগুস্তুস পৃথক ক...   \n","4  Sentence: 10000  শো স্টপারে তাদের বেকড আলাস্কা করতে সাড়ে চার ঘ...   \n","\n","                                          Tag  \n","0                 [0, 0, 0, 0, 0, 0, 0, 0, 1]  \n","1                       [0, 0, 0, 0, 3, 4, 0]  \n","2                    [5, 0, 0, 0, 0, 0, 0, 0]  \n","3  [0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0]  \n","4         [0, 0, 0, 11, 12, 0, 0, 0, 0, 0, 0]  "],"text/html":["\n","  <div id=\"df-63e59e60-da7c-48cd-a68b-0cde91e8a93a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence #</th>\n","      <th>Word</th>\n","      <th>Tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sentence: 1</td>\n","      <td>২০১৮ এর সেরা বর্ণানুক্রমিকভাবে তালিকাভুক্ত র‍্...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sentence: 10</td>\n","      <td>সিনেমায় গানটির বৈশিষ্ট্য রয়েছে রাস্তা যাত্রা ।</td>\n","      <td>[0, 0, 0, 0, 3, 4, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sentence: 100</td>\n","      <td>করে বাদ্যযন্ত্রের থিম এবং চলচ্চিত্রের জন্য প্র...</td>\n","      <td>[5, 0, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sentence: 1000</td>\n","      <td>প্রতিষ্ঠান ২২১১ ইঙ্গিত করে যে আউগুস্তুস পৃথক ক...</td>\n","      <td>[0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sentence: 10000</td>\n","      <td>শো স্টপারে তাদের বেকড আলাস্কা করতে সাড়ে চার ঘ...</td>\n","      <td>[0, 0, 0, 11, 12, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-63e59e60-da7c-48cd-a68b-0cde91e8a93a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-63e59e60-da7c-48cd-a68b-0cde91e8a93a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-63e59e60-da7c-48cd-a68b-0cde91e8a93a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":50}]},{"cell_type":"code","source":["def align_label(df):\n","  for row in tqdm(range(df.shape[0])):\n","    text = df['Word'][row]\n","    Tag = df['Tag'][row]\n","    inputs = tokenizer(text, return_tensors='pt')\n","    tokenized = tokenizer.convert_ids_to_tokens([i.item() for i in inputs['input_ids'].squeeze() if i > 1])\n","    i = 0\n","    j = 0\n","    new_tag = []\n","    prev_tag = 0\n","    while i < len(tokenized):\n","      if tokenized[i].startswith('['): \n","        new_tag.append(0)\n","      elif tokenized[i].startswith('#'):\n","        if prev_tag % 2 != 0:\n","          new_tag.append(prev_tag+1)\n","        else:\n","          new_tag.append(prev_tag)\n","      else:\n","        if tokenized[i] == '.' or tokenized[i] == '′':\n","          new_tag.append(Tag[j])\n","          prev_tag = Tag[j]\n","        else:\n","          new_tag.append(Tag[j])\n","          prev_tag = Tag[j]\n","          j+=1\n","      i+=1\n","    df['Tag'][row] = new_tag\n","  return df\n"],"metadata":{"id":"VMVtxrHIbjNT","executionInfo":{"status":"ok","timestamp":1683399587207,"user_tz":-360,"elapsed":548,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":51,"outputs":[]},{"cell_type":"code","source":["df_val = align_label(df_val)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Gjg2tNYb2Ie","executionInfo":{"status":"ok","timestamp":1683399607453,"user_tz":-360,"elapsed":1918,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"ac104134-591a-4807-a722-f28d0820a07e"},"execution_count":52,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 801/801 [00:01<00:00, 590.82it/s]\n"]}]},{"cell_type":"code","source":["df_train = align_label(df_train)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cTdoacBwb2FQ","executionInfo":{"status":"ok","timestamp":1683399631788,"user_tz":-360,"elapsed":20512,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"4e49bb66-2761-4b89-f001-c0daebd18641"},"execution_count":53,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 15301/15301 [00:20<00:00, 749.12it/s] \n"]}]},{"cell_type":"code","source":["df_test = align_label(df_test)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vLylTFo8b6Ev","executionInfo":{"status":"ok","timestamp":1683407056481,"user_tz":-360,"elapsed":140842,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"5eb45cb2-ca73-4217-f82b-f850de9ec434"},"execution_count":137,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 133114/133114 [02:20<00:00, 946.36it/s] \n"]}]},{"cell_type":"code","source":["def one_hot_encode_list(lst, pad = False):\n","    \"\"\"\n","    One-hot encodes each element in a Python list and returns a tensor containing the one-hot encodings.\n","    \n","    Args:\n","    - lst: A Python list\n","    \n","    Returns:\n","    - A PyTorch tensor with shape (len(lst), 13), where each row represents the one-hot encoding of an element in the input list.\n","    \"\"\"\n","    one_hot_tensors = torch.zeros(len(lst), 13)\n","    for i, elem in enumerate(lst):\n","        one_hot = torch.zeros(13)\n","        one_hot[elem] = 1\n","        one_hot_tensors[i] = one_hot\n","    if pad:\n","      tensor = one_hot_tensors\n","      current_size = tensor.size(0)\n","      if current_size >= 64:\n","          return tensor[:64, :]  # if the tensor is larger than (64, 13), truncate it\n","      \n","      padded_tensor = torch.zeros((64, 13))\n","      padded_tensor[:current_size, :] = tensor  # copy the input tensor to the padded tensor\n","      return padded_tensor\n","    return one_hot_tensors\n","\n","\n","one_hot_encode_list([0, 0, 0, 0, 3, 4, 0],False).size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yTP7H0A5-0of","executionInfo":{"status":"ok","timestamp":1683399631789,"user_tz":-360,"elapsed":28,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"376a82ef-0d85-415d-9232-baf9f9150d32"},"execution_count":54,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([7, 13])"]},"metadata":{},"execution_count":54}]},{"cell_type":"code","source":["# def tokenized_df(text):\n","#     inputs = tokenizer(text, max_length = 64, padding = 'max_length', return_tensors='pt')\n","#     input_ids = inputs['input_ids']\n","#     return input_ids\n","\n","# def tokenized_df1(text):\n","#     inputs = tokenizer(text, max_length = 64, padding = 'max_length', return_tensors='pt')\n","#     attention_mask = inputs['attention_mask']\n","#     return attention_mask\n","# def tokenized_df2(text):\n","#     gazetteer = Gazetteer(text).unsqueeze(0)\n","#     return gazetteer"],"metadata":{"id":"B1UgpyqfXVLu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# df_val['input_ids'] =  df_val['Word'].apply(lambda x: tokenized_df(x))\n","# df_val['attention_mask'] =  df_val['Word'].apply(lambda x: tokenized_df1(x))\n","# df_val['gazetteer'] =  df_val['Word'].apply(lambda x: tokenized_df2(x))\n","# df_train['input_ids'] = df_train['Word'].apply(lambda x: tokenized_df(x))\n","# df_train['attention_mask'] = df_train['Word'].apply(lambda x: tokenized_df1(x))\n","# df_train['gazetteer'] = df_train['Word'].apply(lambda x: tokenized_df2(x))"],"metadata":{"id":"9hePzPudX_Q4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_val['Tag'] =  df_val['Tag'].apply(lambda x: one_hot_encode_list(x))\n","df_train['Tag'] =  df_train['Tag'].apply(lambda x: one_hot_encode_list(x))"],"metadata":{"id":"4dZQtGunAKP8","executionInfo":{"status":"ok","timestamp":1683399644236,"user_tz":-360,"elapsed":5218,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":55,"outputs":[]},{"cell_type":"code","source":["df_test['Tag'] =  df_test['Tag'].apply(lambda x: one_hot_encode_list(x))"],"metadata":{"id":"nRpxo_pX30Ga","executionInfo":{"status":"ok","timestamp":1683407075195,"user_tz":-360,"elapsed":17037,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":138,"outputs":[]},{"cell_type":"code","source":["df_train.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"c3uYaweVAYj_","executionInfo":{"status":"ok","timestamp":1683399645021,"user_tz":-360,"elapsed":797,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"c331fb98-c0a8-46cd-80df-d4bb4db5a73b"},"execution_count":56,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        Sentence #                                               Word  \\\n","0      Sentence: 1  ২০১৮ এর সেরা বর্ণানুক্রমিকভাবে তালিকাভুক্ত র‍্...   \n","1     Sentence: 10   সিনেমায় গানটির বৈশিষ্ট্য রয়েছে রাস্তা যাত্রা ।   \n","2    Sentence: 100  করে বাদ্যযন্ত্রের থিম এবং চলচ্চিত্রের জন্য প্র...   \n","3   Sentence: 1000  প্রতিষ্ঠান ২২১১ ইঙ্গিত করে যে আউগুস্তুস পৃথক ক...   \n","4  Sentence: 10000  শো স্টপারে তাদের বেকড আলাস্কা করতে সাড়ে চার ঘ...   \n","\n","                                                 Tag  \n","0  [[tensor(1.), tensor(0.), tensor(0.), tensor(0...  \n","1  [[tensor(1.), tensor(0.), tensor(0.), tensor(0...  \n","2  [[tensor(1.), tensor(0.), tensor(0.), tensor(0...  \n","3  [[tensor(1.), tensor(0.), tensor(0.), tensor(0...  \n","4  [[tensor(1.), tensor(0.), tensor(0.), tensor(0...  "],"text/html":["\n","  <div id=\"df-06060a19-e9c3-4510-9be2-4fb1c44b88cc\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence #</th>\n","      <th>Word</th>\n","      <th>Tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sentence: 1</td>\n","      <td>২০১৮ এর সেরা বর্ণানুক্রমিকভাবে তালিকাভুক্ত র‍্...</td>\n","      <td>[[tensor(1.), tensor(0.), tensor(0.), tensor(0...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sentence: 10</td>\n","      <td>সিনেমায় গানটির বৈশিষ্ট্য রয়েছে রাস্তা যাত্রা ।</td>\n","      <td>[[tensor(1.), tensor(0.), tensor(0.), tensor(0...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sentence: 100</td>\n","      <td>করে বাদ্যযন্ত্রের থিম এবং চলচ্চিত্রের জন্য প্র...</td>\n","      <td>[[tensor(1.), tensor(0.), tensor(0.), tensor(0...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sentence: 1000</td>\n","      <td>প্রতিষ্ঠান ২২১১ ইঙ্গিত করে যে আউগুস্তুস পৃথক ক...</td>\n","      <td>[[tensor(1.), tensor(0.), tensor(0.), tensor(0...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sentence: 10000</td>\n","      <td>শো স্টপারে তাদের বেকড আলাস্কা করতে সাড়ে চার ঘ...</td>\n","      <td>[[tensor(1.), tensor(0.), tensor(0.), tensor(0...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-06060a19-e9c3-4510-9be2-4fb1c44b88cc')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-06060a19-e9c3-4510-9be2-4fb1c44b88cc button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-06060a19-e9c3-4510-9be2-4fb1c44b88cc');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":56}]},{"cell_type":"code","source":[],"metadata":{"id":"fBxQhISVbn1N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#Model"],"metadata":{"id":"Pk4JvLo0YzcB"}},{"cell_type":"code","source":["device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","device"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TkuLIchdYz_Z","executionInfo":{"status":"ok","timestamp":1683398595649,"user_tz":-360,"elapsed":4,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"fd75a241-a5a4-477c-f1a9-9e0d54dbc28c"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["class NERClassification(nn.Module):\n","  def __init__(self, n_classes):\n","    super(NERClassification, self).__init__()\n","    self.bert = ElectraForTokenClassification.from_pretrained(model_name, output_hidden_states=True)\n","    self.drop = nn.Dropout(p=0.1)\n","    self.out = nn.Linear(self.bert.config.hidden_size, n_classes)\n","    self.gOut = nn.Linear(n_classes,n_classes)\n","    self.final_out = nn.Linear(2*n_classes, n_classes)\n","    self.softmax = nn.Softmax(dim = 1)\n","\n","  def forward(self, input_ids, attention_mask, gazetteer):\n","    pooled_output = self.bert(\n","      input_ids=input_ids,\n","      attention_mask=attention_mask\n","    )\n","\n","    hidden_states = pooled_output.hidden_states\n","\n","    # print(hidden_states)\n","    \n","    layer6 = hidden_states[6]\n","    layer12 = hidden_states[12]\n","    layer18 = hidden_states[18]\n","\n","\n","    averaged_hidden_states = torch.mean(torch.stack([layer6, layer12, layer18]), dim=0)\n","\n","    # print(pooled_output)\n","\n","    output = self.drop(averaged_hidden_states)\n","    output = self.out(output)\n","    goutput = self.gOut(gazetteer)\n","    final_output = torch.concat((output,goutput), dim = 2)\n","    final_output = self.final_out(final_output)\n","    final_output = self.softmax(final_output)\n","    return final_output"],"metadata":{"id":"a_mLbA0yY6dn","executionInfo":{"status":"ok","timestamp":1683398616251,"user_tz":-360,"elapsed":3,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["model = NERClassification(n_classes=13)"],"metadata":{"id":"k7rTLJZ-Y9mG","executionInfo":{"status":"ok","timestamp":1683398645360,"user_tz":-360,"elapsed":24436,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["text = \"সিনেমায় গানটির বৈশিষ্ট্য রয়েছে রাস্তা যাত্রা ।\"\n","inputs = tokenizer(text, return_tensors='pt')\n"],"metadata":{"id":"bn64hkOsZCM2","executionInfo":{"status":"ok","timestamp":1683398696691,"user_tz":-360,"elapsed":452,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["inputs['input_ids']"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5fvHIUGrZDbc","executionInfo":{"status":"ok","timestamp":1683398700739,"user_tz":-360,"elapsed":3,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"ccdb5ab5-9bf8-4d48-f971-b8239ffb4277"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[    2, 13509, 20928,  7887,  1401,  2772,  5078,   205,     3]])"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["inputs['attention_mask'].size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F_VPyClSbQN8","executionInfo":{"status":"ok","timestamp":1683398705229,"user_tz":-360,"elapsed":433,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"f33ce2aa-a704-4856-b3ca-15a6308b6e47"},"execution_count":28,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 9])"]},"metadata":{},"execution_count":28}]},{"cell_type":"code","source":["x = Gazetteer(text)"],"metadata":{"id":"ufb5PVS8aeq_","executionInfo":{"status":"ok","timestamp":1683398707454,"user_tz":-360,"elapsed":3,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":29,"outputs":[]},{"cell_type":"code","source":["x"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yGCifjwLYc4S","executionInfo":{"status":"ok","timestamp":1683398711737,"user_tz":-360,"elapsed":3,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"0b880bd3-f6be-4a24-947e-67e64ffb7a50"},"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n","        [1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"]},"metadata":{},"execution_count":30}]},{"cell_type":"code","source":["\n","\n","text = \"সিনেমায় গানটির বৈশিষ্ট্য রয়েছে রাস্তা যাত্রা ।\"\n","inputs = tokenizer(text, return_tensors='pt')\n","\n","input_ids = inputs['input_ids'].to(device)\n","attention_mask = inputs['attention_mask'].to(device)\n","gazetteer = Gazetteer(text).unsqueeze(0).to(device)\n","# Run the model\n","outputs = model(input_ids=input_ids, attention_mask=attention_mask, gazetteer = gazetteer)\n","\n","print(outputs.size())\n","\n","# Get the predicted label\n","x, predicted_label = torch.max(outputs, dim=2)\n","\n","predicted_label\n","\n","# Print the predicted label\n","# print(predicted_label.item())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T1llOGuWY_gz","executionInfo":{"status":"ok","timestamp":1683399664825,"user_tz":-360,"elapsed":6,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"88bdda9e-28e6-41a3-8545-fde982d52d24"},"execution_count":58,"outputs":[{"output_type":"stream","name":"stdout","text":["torch.Size([1, 9, 13])\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([[ 5, 12,  5, 11,  3,  0,  0,  3,  5]], device='cuda:0')"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["from sklearn.metrics import classification_report\n","print(classification_report(predicted_label[0].to('cpu'),predicted_label[0].to('cpu'), output_dict = True)['macro avg']['f1-score'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N5l-MgOgZbEc","executionInfo":{"status":"ok","timestamp":1683400160891,"user_tz":-360,"elapsed":437,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"59e5288f-5905-4ec9-b2c7-ccaa59c1bcea"},"execution_count":69,"outputs":[{"output_type":"stream","name":"stdout","text":["1.0\n"]}]},{"cell_type":"code","source":["print(classification_report([0,0,0,3,4,4],[0,0,0,4,4,5]))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"O_XO2jUyawkF","executionInfo":{"status":"ok","timestamp":1683399346667,"user_tz":-360,"elapsed":3,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"5294fc5d-2d5c-4e40-b9b2-5f0d5811adf4"},"execution_count":46,"outputs":[{"output_type":"stream","name":"stdout","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00         3\n","           3       0.00      0.00      0.00         1\n","           4       0.50      0.50      0.50         2\n","           5       0.00      0.00      0.00         0\n","\n","    accuracy                           0.67         6\n","   macro avg       0.38      0.38      0.38         6\n","weighted avg       0.67      0.67      0.67         6\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.10/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}]},{"cell_type":"code","source":["from torch.utils.data import DataLoader\n","from transformers import AdamW\n","\n","device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","model.to(device)\n","model.train()\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Iza7_6PPgi1C","executionInfo":{"status":"ok","timestamp":1683398769650,"user_tz":-360,"elapsed":701,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"9bf383ac-f22b-4778-a1e0-950f0c9751e2"},"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["NERClassification(\n","  (bert): ElectraForTokenClassification(\n","    (electra): ElectraModel(\n","      (embeddings): ElectraEmbeddings(\n","        (word_embeddings): Embedding(32000, 1024, padding_idx=0)\n","        (position_embeddings): Embedding(512, 1024)\n","        (token_type_embeddings): Embedding(2, 1024)\n","        (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","        (dropout): Dropout(p=0.1, inplace=False)\n","      )\n","      (encoder): ElectraEncoder(\n","        (layer): ModuleList(\n","          (0-23): 24 x ElectraLayer(\n","            (attention): ElectraAttention(\n","              (self): ElectraSelfAttention(\n","                (query): Linear(in_features=1024, out_features=1024, bias=True)\n","                (key): Linear(in_features=1024, out_features=1024, bias=True)\n","                (value): Linear(in_features=1024, out_features=1024, bias=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","              (output): ElectraSelfOutput(\n","                (dense): Linear(in_features=1024, out_features=1024, bias=True)\n","                (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","                (dropout): Dropout(p=0.1, inplace=False)\n","              )\n","            )\n","            (intermediate): ElectraIntermediate(\n","              (dense): Linear(in_features=1024, out_features=4096, bias=True)\n","              (intermediate_act_fn): GELUActivation()\n","            )\n","            (output): ElectraOutput(\n","              (dense): Linear(in_features=4096, out_features=1024, bias=True)\n","              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","            )\n","          )\n","        )\n","      )\n","    )\n","    (dropout): Dropout(p=0.1, inplace=False)\n","    (classifier): Linear(in_features=1024, out_features=13, bias=True)\n","  )\n","  (drop): Dropout(p=0.1, inplace=False)\n","  (out): Linear(in_features=1024, out_features=13, bias=True)\n","  (gOut): Linear(in_features=13, out_features=13, bias=True)\n","  (final_out): Linear(in_features=26, out_features=13, bias=True)\n","  (softmax): Softmax(dim=1)\n",")"]},"metadata":{},"execution_count":34}]},{"cell_type":"code","source":["from torch.nn import CrossEntropyLoss\n","\n","loss1 = CrossEntropyLoss()\n","optim = AdamW(model.parameters(), lr=5e-5)\n","CS_SCORE = []\n","\n","for epoch in range(10):\n","  c1 = []\n","  for i in tqdm(range((df_train.shape[0]))):\n","    text = df_train['Word'][i]\n","    label = df_train['Tag'][i].to(device)\n","    g = Gazetteer(df_train['Word'][i]).unsqueeze(0).to(device)\n","    inputs = tokenizer(text, return_tensors='pt')\n","    inp = inputs['input_ids'].to(device)\n","    a = inputs['attention_mask'].to(device)\n","    if inp.size()[1] != g.size()[1]:\n","      continue\n","    outputs = model(input_ids = inp, attention_mask=a, gazetteer = g)\n","    loss = loss1(outputs[0],label)\n","    if i % 100 == 0:\n","      optim.zero_grad()\n","    loss.backward()\n","    optim.step()\n","  print(loss)\n","  print(\"Running Test\")\n","  mac_f1 = []\n","  jhamela = 0\n","  for i in tqdm(range((df_val.shape[0]))):\n","    text = df_val['Word'][i]\n","    label = df_val['Tag'][i].to(device)\n","    g = Gazetteer(df_val['Word'][i]).unsqueeze(0).to(device)\n","    inputs = tokenizer(text, return_tensors='pt')\n","    inp = inputs['input_ids'].to(device)\n","    a = inputs['attention_mask'].to(device)\n","    if inp.size()[1] != g.size()[1]:\n","      jhamela += 1\n","      continue\n","    outputs = model(input_ids = inp, attention_mask=a, gazetteer = g)\n","    _, predicted_label = torch.max(outputs, dim=2)\n","    _, real = torch.max(label, dim=1)\n","    c1.append(classification_report(predicted_label[0].to('cpu'),real.to('cpu'), output_dict = True, zero_division=0))\n","    mac_f1.append(classification_report(predicted_label[0].to('cpu'),real.to('cpu'), output_dict = True, zero_division=0)['macro avg']['f1-score'])\n","  print(\"MACRO F1 = \", sum(mac_f1) / (len(mac_f1)-jhamela))\n","  if epoch+1 % 3 == 0:\n","    with open('single model e{}.pkl'.format(epoch+1), 'wb') as f:\n","      pickle.dump(model, f)\n","\n","\n","model.eval()\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":376},"id":"MvdHwGTnY0bd","executionInfo":{"status":"error","timestamp":1683406039548,"user_tz":-360,"elapsed":3096575,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"039bdfb8-8320-4515-edf4-4b7923ad96ed"},"execution_count":116,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","100%|██████████| 15301/15301 [40:16<00:00,  6.33it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Running Test\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 801/801 [00:48<00:00, 16.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["MACRO F1 =  0.1285671379313281\n"]},{"output_type":"stream","name":"stderr","text":[" 26%|██▌       | 3979/15301 [10:31<29:55,  6.30it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-116-1fda2c541079>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Tag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGazetteer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Word'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["import torch\n","import torchmetrics\n","\n","# Assuming y_true and y_pred are PyTorch tensors\n","y_true = torch.tensor([0, 1, 2, 0, 1, 2])\n","y_pred = torch.tensor([0, 2, 1, 0, 2, 1])\n","\n","# Calculate F1 score using torchmetrics\n","f1 = torchmetrics.functional.f1_score(y_pred, y_true, task = 'multiclass', num_classes=13, average='micro', zero_division = 1)\n","\n","print(f\"F1 score: {f1:.3f}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":235},"id":"NTmGuRm71dEF","executionInfo":{"status":"error","timestamp":1683406676607,"user_tz":-360,"elapsed":10,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"1c1642ac-7a91-4862-9549-755795291ab0"},"execution_count":133,"outputs":[{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-133-15c916868c08>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Calculate F1 score using torchmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'multiclass'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m13\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'micro'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzero_division\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"F1 score: {f1:.3f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: f1_score() got an unexpected keyword argument 'zero_division'"]}]},{"cell_type":"code","source":["for i in tqdm(range((df_test.shape[0]))):\n","    text = df_test['Word'][i]\n","    label = df_test['Tag'][i].to(device)\n","    g = Gazetteer(df_test['Word'][i]).unsqueeze(0).to(device)\n","    inputs = tokenizer(text, return_tensors='pt')\n","    inp = inputs['input_ids'].to(device)\n","    a = inputs['attention_mask'].to(device)\n","    if inp.size()[1] != g.size()[1]:\n","      jhamela += 1\n","      continue\n","    outputs = model(input_ids = inp, attention_mask=a, gazetteer = g)\n","    _, predicted_label = torch.max(outputs, dim=2)\n","    _, real = torch.max(label, dim=1)\n","    mac_f1.append(classification_report(predicted_label[0].to('cpu'),real.to('cpu'), output_dict = True, zero_division=0)['macro avg']['f1-score'])\n","print(\"MACRO F1 = \", sum(mac_f1) / (len(mac_f1)-jhamela))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"id":"kufu4jy20dDc","executionInfo":{"status":"error","timestamp":1683407253590,"user_tz":-360,"elapsed":19756,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"ef3a785a-b410-46ea-a5aa-5322798328bb"},"execution_count":140,"outputs":[{"output_type":"stream","name":"stderr","text":["  0%|          | 190/133114 [00:19<3:49:19,  9.66it/s]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-140-07a75c8a0870>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m       \u001b[0mjhamela\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgazetteer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-23-80285b7e9225>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, gazetteer)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgazetteer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     pooled_output = self.bert(\n\u001b[0m\u001b[1;32m     13\u001b[0m       \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1298\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m         discriminator_hidden_states = self.electra(\n\u001b[0m\u001b[1;32m   1301\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings_project\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 919\u001b[0;31m         hidden_states = self.encoder(\n\u001b[0m\u001b[1;32m    920\u001b[0m             \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    921\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextended_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    586\u001b[0m                 )\n\u001b[1;32m    587\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m                 layer_outputs = layer_module(\n\u001b[0m\u001b[1;32m    589\u001b[0m                     \u001b[0mhidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m                     \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpresent_key_value\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mcross_attn_present_key_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m         layer_output = apply_chunking_to_forward(\n\u001b[0m\u001b[1;32m    515\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m         )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/pytorch_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    524\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    525\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","source":["g.size()[1] != label.size()[0]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"doljOVTkhqCG","executionInfo":{"status":"ok","timestamp":1683401358780,"user_tz":-360,"elapsed":458,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"e81bc0b6-4b21-4ead-8d1c-98f59547b3c3"},"execution_count":85,"outputs":[{"output_type":"execute_result","data":{"text/plain":["False"]},"metadata":{},"execution_count":85}]},{"cell_type":"code","source":["g.size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Gy9iIdH5oWFu","executionInfo":{"status":"ok","timestamp":1683402879214,"user_tz":-360,"elapsed":5,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"926533b6-c0cf-4739-91fc-f55deb74a6fc"},"execution_count":113,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 12, 13])"]},"metadata":{},"execution_count":113}]},{"cell_type":"code","source":[],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ui-GUEb4n-pP","executionInfo":{"status":"ok","timestamp":1683402890353,"user_tz":-360,"elapsed":4,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"a909d2a3-748c-4e90-ac19-41d8f00aa35d"},"execution_count":115,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":115}]},{"cell_type":"code","source":["Gazetteer(\"১৯২৭ বেন্টলি ৪1⁄2 লিটার অনুরূপ ইঞ্জিন ডিজাইনের ছিল\").size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eeHWMMfRhjkf","executionInfo":{"status":"ok","timestamp":1683402779414,"user_tz":-360,"elapsed":773,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"e2b08909-2ca1-4802-f151-8ee70c2d6249"},"execution_count":108,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([12, 13])"]},"metadata":{},"execution_count":108}]},{"cell_type":"code","source":["from torch.nn import BCELoss\n","\n","loss1 = BCELoss()\n","optim = AdamW(model.parameters(), lr=5e-5)\n","\n","for epoch in range(3):\n","    for j in tqdm(range(df_train.shape[0])):\n","        optim.zero_grad()\n","        i,a,g, label = df_train['input_ids'][j].to(device) , df_train['attention_mask'][j].to(device) ,df_train['gazetteer'][j].to(device) ,df_train['Tag'][j].unsqueeze(0).to(device)\n","        outputs = model(input_ids = i, attention_mask=a, gazetteer = g)\n","        loss = loss1(outputs,label)\n","        if j % 100 == 0:\n","          print(loss)\n","        loss.backward()\n","        optim.step()\n","\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RmQUjXNqWSB-","outputId":"0e8029be-76ff-4eea-f81e-2044ef087378"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n","  warnings.warn(\n","  0%|          | 1/15301 [00:00<34:25,  7.41it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0388, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["  1%|          | 102/15301 [00:14<33:23,  7.59it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0334, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["  1%|▏         | 202/15301 [00:31<37:25,  6.73it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0407, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["  2%|▏         | 301/15301 [00:45<40:16,  6.21it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0347, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["  3%|▎         | 401/15301 [00:58<37:47,  6.57it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0953, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["  3%|▎         | 501/15301 [01:12<36:45,  6.71it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0211, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["  4%|▍         | 601/15301 [01:25<35:29,  6.90it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0730, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["  5%|▍         | 702/15301 [01:40<31:48,  7.65it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0384, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["  5%|▌         | 801/15301 [01:56<33:48,  7.15it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0612, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["  6%|▌         | 902/15301 [02:10<31:54,  7.52it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.1020, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["  7%|▋         | 1002/15301 [02:23<31:10,  7.64it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0309, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["  7%|▋         | 1102/15301 [02:37<30:41,  7.71it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0977, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["  8%|▊         | 1202/15301 [02:51<30:46,  7.64it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0254, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["  9%|▊         | 1302/15301 [03:05<30:27,  7.66it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0872, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":["  9%|▉         | 1402/15301 [03:19<30:20,  7.64it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0385, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 10%|▉         | 1502/15301 [03:33<30:18,  7.59it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0433, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 10%|█         | 1602/15301 [03:46<30:54,  7.39it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0608, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 11%|█         | 1701/15301 [04:00<35:51,  6.32it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0454, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 12%|█▏        | 1801/15301 [04:14<33:22,  6.74it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0317, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 12%|█▏        | 1901/15301 [04:27<34:19,  6.51it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0483, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 13%|█▎        | 2001/15301 [04:42<36:32,  6.07it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0497, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 14%|█▎        | 2102/15301 [04:56<28:17,  7.78it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0259, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 14%|█▍        | 2202/15301 [05:10<28:37,  7.63it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0467, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 15%|█▌        | 2302/15301 [05:24<28:19,  7.65it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0736, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 16%|█▌        | 2402/15301 [05:38<27:43,  7.76it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.1012, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 16%|█▋        | 2502/15301 [05:52<27:41,  7.70it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.1011, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 17%|█▋        | 2601/15301 [06:06<31:39,  6.69it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0559, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 18%|█▊        | 2702/15301 [06:20<28:52,  7.27it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0568, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 18%|█▊        | 2801/15301 [06:33<32:42,  6.37it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0642, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 19%|█▉        | 2901/15301 [06:47<30:54,  6.69it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0567, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 20%|█▉        | 3001/15301 [07:01<30:32,  6.71it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0750, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 20%|██        | 3101/15301 [07:14<27:05,  7.51it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0351, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 21%|██        | 3201/15301 [07:28<27:20,  7.38it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0413, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 22%|██▏       | 3302/15301 [07:42<26:35,  7.52it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0409, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 22%|██▏       | 3402/15301 [07:56<26:17,  7.54it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0897, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 23%|██▎       | 3502/15301 [08:10<25:31,  7.70it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0501, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 24%|██▎       | 3601/15301 [08:24<25:27,  7.66it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0616, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 24%|██▍       | 3702/15301 [08:38<25:38,  7.54it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0507, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 25%|██▍       | 3802/15301 [08:52<25:05,  7.64it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0237, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 25%|██▌       | 3901/15301 [09:05<26:04,  7.29it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0478, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 26%|██▌       | 4001/15301 [09:25<30:36,  6.15it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0884, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 27%|██▋       | 4102/15301 [09:41<24:15,  7.70it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0398, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 27%|██▋       | 4202/15301 [09:55<24:04,  7.69it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0283, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 28%|██▊       | 4302/15301 [10:08<24:00,  7.64it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0240, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 29%|██▉       | 4401/15301 [10:23<31:37,  5.74it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0531, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 29%|██▉       | 4501/15301 [10:37<28:50,  6.24it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.1016, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 30%|███       | 4601/15301 [10:53<29:17,  6.09it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0365, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 31%|███       | 4701/15301 [11:08<28:22,  6.23it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0442, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 31%|███▏      | 4801/15301 [11:21<26:20,  6.64it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0953, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 32%|███▏      | 4901/15301 [11:35<25:42,  6.74it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0506, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 33%|███▎      | 5002/15301 [11:49<22:48,  7.53it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0284, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 33%|███▎      | 5102/15301 [12:03<22:20,  7.61it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0379, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 34%|███▍      | 5202/15301 [12:16<22:06,  7.61it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0366, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 35%|███▍      | 5301/15301 [12:30<21:47,  7.65it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0247, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 35%|███▌      | 5402/15301 [12:44<21:43,  7.59it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0402, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 36%|███▌      | 5502/15301 [12:59<21:26,  7.62it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0961, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 37%|███▋      | 5602/15301 [13:12<20:57,  7.72it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0363, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 37%|███▋      | 5701/15301 [13:26<20:48,  7.69it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0951, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 38%|███▊      | 5802/15301 [13:40<21:16,  7.44it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0237, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 39%|███▊      | 5901/15301 [13:54<25:11,  6.22it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0545, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 39%|███▉      | 6001/15301 [14:07<23:35,  6.57it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0291, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 40%|███▉      | 6101/15301 [14:21<22:42,  6.75it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0346, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 41%|████      | 6201/15301 [14:34<21:33,  7.04it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0871, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 41%|████      | 6302/15301 [14:51<19:40,  7.62it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0391, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 42%|████▏     | 6402/15301 [15:05<19:17,  7.69it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0267, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 42%|████▏     | 6502/15301 [15:19<19:12,  7.64it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0295, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 43%|████▎     | 6602/15301 [15:34<19:03,  7.61it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0632, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 44%|████▍     | 6702/15301 [15:48<18:30,  7.74it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0365, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 44%|████▍     | 6801/15301 [16:01<18:32,  7.64it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0547, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 45%|████▌     | 6902/15301 [16:15<20:13,  6.92it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0706, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 46%|████▌     | 7001/15301 [16:29<21:06,  6.55it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0475, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 46%|████▋     | 7101/15301 [16:42<20:25,  6.69it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0277, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 47%|████▋     | 7201/15301 [16:56<19:40,  6.86it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0264, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 48%|████▊     | 7302/15301 [17:09<17:20,  7.69it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0305, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 48%|████▊     | 7402/15301 [17:23<17:07,  7.69it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.1106, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 49%|████▉     | 7501/15301 [17:37<17:00,  7.64it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0814, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 50%|████▉     | 7602/15301 [17:51<16:46,  7.65it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0211, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 50%|█████     | 7701/15301 [18:04<16:52,  7.51it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0406, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 51%|█████     | 7802/15301 [18:18<16:09,  7.74it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0508, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 52%|█████▏    | 7902/15301 [18:32<16:22,  7.53it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0269, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 52%|█████▏    | 8002/15301 [18:46<16:51,  7.22it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0476, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 53%|█████▎    | 8101/15301 [18:59<18:55,  6.34it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0537, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 54%|█████▎    | 8201/15301 [19:13<17:53,  6.61it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0316, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 54%|█████▍    | 8301/15301 [19:27<17:01,  6.85it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0288, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 55%|█████▍    | 8401/15301 [19:41<17:47,  6.46it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0300, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 56%|█████▌    | 8502/15301 [19:55<14:47,  7.66it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0280, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 56%|█████▌    | 8602/15301 [20:09<14:32,  7.68it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0243, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 57%|█████▋    | 8702/15301 [20:23<14:24,  7.63it/s]"]},{"output_type":"stream","name":"stdout","text":["tensor(0.0308, device='cuda:0', grad_fn=<BinaryCrossEntropyBackward0>)\n"]},{"output_type":"stream","name":"stderr","text":[" 57%|█████▋    | 8741/15301 [20:28<16:18,  6.70it/s]"]}]},{"cell_type":"code","source":["class NERDataset(Dataset):\n","  def __init__(self,df):\n","    self.input_ids = df['input_ids']\n","    self.attention_mask = df['attention_mask']\n","    self.gazetteer = df['gazetteer']\n","    self.label = df['Tag']\n","    self.n_samples = df.shape[0]\n","\n","  def __getitem__(self, idx):\n","    return self.input_ids[idx].to(device),self.attention_mask[idx].to(device),self.gazetteer[idx].to(device),self.label[idx].to(device)\n","  \n","  def __len__(self):\n","    return self.n_samples\n","    "],"metadata":{"id":"PNTHTC5wkUr6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset = NERDataset(df_train)"],"metadata":{"id":"nKWSNb5dDYT0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataset.n_samples"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"EkfJmNh3FE4r","executionInfo":{"status":"ok","timestamp":1682940844360,"user_tz":-360,"elapsed":5,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"8d0d3270-2e05-403f-d9f0-fbafa20fb7b2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["15301"]},"metadata":{},"execution_count":58}]},{"cell_type":"code","source":["import pickle"],"metadata":{"id":"e6LpN9LYWQsw","executionInfo":{"status":"ok","timestamp":1683401907667,"user_tz":-360,"elapsed":2,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}}},"execution_count":97,"outputs":[]},{"cell_type":"code","source":["train_loader = DataLoader(dataset = train_dataset, batch_size=1, shuffle=True)"],"metadata":{"id":"mdkocqalE5Zj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.nn import BCELoss\n","\n","loss = BCELoss()\n","optim = AdamW(model.parameters(), lr=5e-5)\n","\n","for epoch in range(3):\n","    for batch in train_loader:\n","        optim.zero_grad()\n","        i,a,g, label = batch\n","        outputs = model(input_ids = i, attention_mask=a, gazetteer = g)\n","        loss = loss(outputs,label)\n","        loss.backward()\n","        optim.step()\n","\n","model.eval()"],"metadata":{"id":"V6hg1Qb7WOCL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.nn import BCELoss\n","\n","loss = BCELoss()\n","optim = AdamW(model.parameters(), lr=5e-5)\n","\n","for epoch in range(3):\n","    for batch in train_loader:\n","        optim.zero_grad()\n","        i,a,g, label = batch\n","        outputs = model(input_ids = i, attention_mask=a, gazetteer = g)\n","        loss = loss(outputs,label)\n","        loss.backward()\n","        optim.step()\n","\n","model.eval()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":415},"id":"vIJCwJBOf_zZ","executionInfo":{"status":"error","timestamp":1682941528089,"user_tz":-360,"elapsed":29,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"c5d60578-3098-4312-c6a2-ba7b0e45781a"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-70-91d188b86d6b>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgazetteer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-67-18b5c1b245cf>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, gazetteer)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgazetteer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     pooled_output,_ = self.bert(\n\u001b[0m\u001b[1;32m     13\u001b[0m       \u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m       \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1298\u001b[0m         \u001b[0mreturn_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_return_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1300\u001b[0;31m         discriminator_hidden_states = self.electra(\n\u001b[0m\u001b[1;32m   1301\u001b[0m             \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1302\u001b[0m             \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/transformers/models/electra/modeling_electra.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You have to specify either input_ids or inputs_embeds\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m         \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0minput_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0minputs_embeds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"]}]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/Bracu/THESIS/Saved Models"],"metadata":{"id":"CjCW00V3hAiL","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1683401886238,"user_tz":-360,"elapsed":539,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"e773314d-d3bb-4672-93a6-76ca97d2d9d2"},"execution_count":95,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Bracu/THESIS/Saved Models\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"ZFbgZvz3kO7g"},"execution_count":null,"outputs":[]}]}