{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1g-_JXFc1fYup8iU-UDfjW5IELsishaGu","timestamp":1680534269995}]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"gpuClass":"standard","widgets":{"application/vnd.jupyter.widget-state+json":{"cb8f68a651694a319f70fddb5f73eec7":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_0267149a4f7744b988c0ff948129fafd","IPY_MODEL_c583e2b3379d4269b30db0489a5614c6","IPY_MODEL_87539224aafa4f949d9b20aee2d83997"],"layout":"IPY_MODEL_240169913a194caea37e6e9a22364a18"}},"0267149a4f7744b988c0ff948129fafd":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_80c30aebfb8546c5bc7f36d7cb727c9b","placeholder":"​","style":"IPY_MODEL_757f2fb5337c4f28a287039a4eaceecb","value":"Downloading (…)okenizer_config.json: 100%"}},"c583e2b3379d4269b30db0489a5614c6":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_34948fcba52548d7b737ac3e34341672","max":119,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c418a8c535754ee883b6ee91d57879df","value":119}},"87539224aafa4f949d9b20aee2d83997":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_142401b7059a4edd804fd7dce8ee788a","placeholder":"​","style":"IPY_MODEL_3b6beea49f8541948a9135f3a5fb8236","value":" 119/119 [00:00&lt;00:00, 4.03kB/s]"}},"240169913a194caea37e6e9a22364a18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"80c30aebfb8546c5bc7f36d7cb727c9b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"757f2fb5337c4f28a287039a4eaceecb":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"34948fcba52548d7b737ac3e34341672":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c418a8c535754ee883b6ee91d57879df":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"142401b7059a4edd804fd7dce8ee788a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"3b6beea49f8541948a9135f3a5fb8236":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"662c757466f242ec82d5a374021ec103":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_bfb3cf69f12b40bda467a6ff699d902e","IPY_MODEL_9c776ce625614f3687ab0f7e236bf00a","IPY_MODEL_cac81c7fb04144398a6f4afac5897314"],"layout":"IPY_MODEL_1b6f053c4a67457fbe1faa0cf688784c"}},"bfb3cf69f12b40bda467a6ff699d902e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_a10d6323d60b47c1b459e19077252979","placeholder":"​","style":"IPY_MODEL_adcd27c175474542b2b3f199163e0230","value":"Downloading (…)lve/main/config.json: 100%"}},"9c776ce625614f3687ab0f7e236bf00a":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_5a219d37890543f4a50d7224e4ab96bd","max":880,"min":0,"orientation":"horizontal","style":"IPY_MODEL_9fea8bca6111489ea9dc1f5c8e22bf30","value":880}},"cac81c7fb04144398a6f4afac5897314":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_520c952de9824b18898e35a786cd911e","placeholder":"​","style":"IPY_MODEL_1278288c122a472d98fea12d59b6fec3","value":" 880/880 [00:00&lt;00:00, 37.2kB/s]"}},"1b6f053c4a67457fbe1faa0cf688784c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a10d6323d60b47c1b459e19077252979":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"adcd27c175474542b2b3f199163e0230":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"5a219d37890543f4a50d7224e4ab96bd":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"9fea8bca6111489ea9dc1f5c8e22bf30":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"520c952de9824b18898e35a786cd911e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"1278288c122a472d98fea12d59b6fec3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d05d84122d52430d9f81db1b1debc13c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e7a65b695866488bb578e846914e478e","IPY_MODEL_99340238d1034f348cd7d66535bd4737","IPY_MODEL_7f8239b7e38147fbad093e5706d4a27c"],"layout":"IPY_MODEL_8c1704fa5565499694b14b583caf88f9"}},"e7a65b695866488bb578e846914e478e":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_371eea0763a54251ab30104358485604","placeholder":"​","style":"IPY_MODEL_7a20335d14c149f799e8bb07077f9e6e","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"99340238d1034f348cd7d66535bd4737":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_79e07bb9bd4b4eb29d06418c59e88b8d","max":528316,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2fae1da67068483a87c025ee7c68d5fe","value":528316}},"7f8239b7e38147fbad093e5706d4a27c":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_2ce80c8d8fab40afa5cd04a8bb33d6f5","placeholder":"​","style":"IPY_MODEL_c8fc7d3efc3d4665ba95f62828ef35d7","value":" 528k/528k [00:00&lt;00:00, 1.98MB/s]"}},"8c1704fa5565499694b14b583caf88f9":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"371eea0763a54251ab30104358485604":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7a20335d14c149f799e8bb07077f9e6e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"79e07bb9bd4b4eb29d06418c59e88b8d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2fae1da67068483a87c025ee7c68d5fe":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"2ce80c8d8fab40afa5cd04a8bb33d6f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c8fc7d3efc3d4665ba95f62828ef35d7":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f9d9a15a829e46d282539263aa258d6c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_9e5a398c144b4202828e91056a39b091","IPY_MODEL_f1546ac39d904d51adbf9711a7b53f1e","IPY_MODEL_e854a920a3ed4500a0462b663648ffce"],"layout":"IPY_MODEL_4957ce9c848b45f2b74c53737a8a30f3"}},"9e5a398c144b4202828e91056a39b091":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f5f3c7730cd645d7ad8430655f1c0141","placeholder":"​","style":"IPY_MODEL_896f323195d34e4f80f5bf45a64d029e","value":"Downloading (…)cial_tokens_map.json: 100%"}},"f1546ac39d904d51adbf9711a7b53f1e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ef4ec114e15d4de8a9f69febf4ed659f","max":112,"min":0,"orientation":"horizontal","style":"IPY_MODEL_19de8f2a76d744aca014440736c03499","value":112}},"e854a920a3ed4500a0462b663648ffce":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5e7f5f9306504a90872df147ba36283c","placeholder":"​","style":"IPY_MODEL_a3c9ab89afb0494e81e7247c321c4f9e","value":" 112/112 [00:00&lt;00:00, 4.27kB/s]"}},"4957ce9c848b45f2b74c53737a8a30f3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"f5f3c7730cd645d7ad8430655f1c0141":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"896f323195d34e4f80f5bf45a64d029e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ef4ec114e15d4de8a9f69febf4ed659f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"19de8f2a76d744aca014440736c03499":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"5e7f5f9306504a90872df147ba36283c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"a3c9ab89afb0494e81e7247c321c4f9e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}},"accelerator":"GPU"},"cells":[{"cell_type":"code","source":["import tensorflow as tf\n","tf.compat.v1.disable_eager_execution()"],"metadata":{"id":"ZS5kovQ18olq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":328},"id":"vkpkHNWjp5Fk","executionInfo":{"status":"error","timestamp":1680624281357,"user_tz":-360,"elapsed":7415,"user":{"displayName":"SAMAN SARKER JOY","userId":"16325955844662716252"}},"outputId":"daff2ef4-48fd-407c-e5f5-e4f0afaf6a76"},"execution_count":1,"outputs":[{"output_type":"error","ename":"MessageError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    175\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m   )\n\u001b[0;32m--> 177\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    102\u001b[0m     ):\n\u001b[1;32m    103\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uiH_fIE7NQSn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680537029143,"user_tz":-360,"elapsed":48418,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"351ea221-a133-431e-80cb-4a88e2d3709b"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.7/468.7 KB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.9/132.9 KB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.8/199.8 KB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 KB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.2/212.2 KB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.6/264.6 KB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.8/158.8 KB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.2/114.2 KB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m46.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 KB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]}],"source":["!pip install datasets -q\n","!pip install tokenizers -q\n","!pip install transformers -q\n","!pip install seqeval -q"]},{"cell_type":"code","source":["!pip install git+https://github.com/csebuetnlp/normalizer"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qqmrcObuN3j8","executionInfo":{"status":"ok","timestamp":1680537047857,"user_tz":-360,"elapsed":18725,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"b6b80af8-9204-403e-fab6-df6bf2b7c2a1"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting git+https://github.com/csebuetnlp/normalizer\n","  Cloning https://github.com/csebuetnlp/normalizer to /tmp/pip-req-build-0cm5ma1b\n","  Running command git clone --filter=blob:none --quiet https://github.com/csebuetnlp/normalizer /tmp/pip-req-build-0cm5ma1b\n","  Resolved https://github.com/csebuetnlp/normalizer to commit d80c3c484e1b80268f2b2dfaf7557fe65e34f321\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: regex in /usr/local/lib/python3.9/dist-packages (from normalizer==0.0.1) (2022.10.31)\n","Collecting emoji==1.4.2\n","  Downloading emoji-1.4.2.tar.gz (184 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.0/185.0 KB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting ftfy==6.0.3\n","  Downloading ftfy-6.0.3.tar.gz (64 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.2/64.2 KB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.9/dist-packages (from ftfy==6.0.3->normalizer==0.0.1) (0.2.6)\n","Building wheels for collected packages: normalizer, emoji, ftfy\n","  Building wheel for normalizer (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for normalizer: filename=normalizer-0.0.1-py3-none-any.whl size=6877 sha256=0375cf5d655ba16729718367d56c4d091efb2d8f4d352010d21eec9c9e9fb678\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-l2sdmqdf/wheels/50/bb/8c/ac1cb7ca5df3b956b2f1cb661b9c774a71c73f0994c606e9fb\n","  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for emoji: filename=emoji-1.4.2-py3-none-any.whl size=186471 sha256=f0fd61fb77d0e33766938103250af6460e21bd49f7c63e32db1ee8e37a88830b\n","  Stored in directory: /root/.cache/pip/wheels/ee/58/81/7879ea1b221a12a46054c29da10a2330bc0dde51d5fb9a6b2b\n","  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for ftfy: filename=ftfy-6.0.3-py3-none-any.whl size=41933 sha256=bc7b9e72f3fa2a208b6e3c0db2f591f0e8e4157bb2c589146d1ba70fe0eac31a\n","  Stored in directory: /root/.cache/pip/wheels/3d/ee/4b/03a4e2e591ea56687aff999edc83827a2ace523baab75b8e41\n","Successfully built normalizer emoji ftfy\n","Installing collected packages: emoji, ftfy, normalizer\n","Successfully installed emoji-1.4.2 ftfy-6.0.3 normalizer-0.0.1\n"]}]},{"cell_type":"code","source":["from transformers import AutoModelForPreTraining, AutoTokenizer, BertModel\n","from normalizer import normalize # pip install git+https://github.com/csebuetnlp/normalizer\n","import torch\n","\n","model = ElectraForPreTraining.from_pretrained(\"/content/drive/MyDrive/Thesis/BERTOUTPUT/checkpoint-9500/\", output_hidden_states = True)"],"metadata":{"id":"bkmYtINkya4G","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680534526476,"user_tz":-360,"elapsed":37100,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"3f0cc9a5-17bb-4034-a4c7-10b0922bb915"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["You are using a model of type electra to instantiate a model of type bert. This is not supported for all configurations of models and can yield errors.\n","Some weights of the model checkpoint at /content/drive/MyDrive/Thesis/BERTOUTPUT/checkpoint-9500/ were not used when initializing BertModel: ['electra.encoder.layer.6.intermediate.dense.weight', 'electra.encoder.layer.20.attention.self.key.weight', 'electra.encoder.layer.17.output.LayerNorm.weight', 'electra.encoder.layer.13.attention.self.query.bias', 'electra.encoder.layer.15.attention.output.dense.weight', 'electra.encoder.layer.20.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.attention.output.LayerNorm.weight', 'electra.encoder.layer.13.attention.self.value.weight', 'electra.encoder.layer.12.attention.self.value.weight', 'electra.encoder.layer.22.attention.self.key.bias', 'electra.encoder.layer.22.attention.output.LayerNorm.bias', 'electra.encoder.layer.9.attention.output.dense.bias', 'electra.encoder.layer.5.attention.output.dense.weight', 'electra.encoder.layer.11.intermediate.dense.weight', 'electra.encoder.layer.2.attention.output.LayerNorm.weight', 'electra.encoder.layer.1.attention.self.key.weight', 'electra.encoder.layer.19.attention.self.key.bias', 'electra.encoder.layer.1.output.LayerNorm.weight', 'electra.encoder.layer.19.intermediate.dense.bias', 'electra.encoder.layer.1.attention.self.key.bias', 'electra.encoder.layer.19.output.LayerNorm.weight', 'electra.encoder.layer.11.output.dense.bias', 'electra.encoder.layer.6.attention.self.value.weight', 'electra.encoder.layer.10.output.LayerNorm.weight', 'electra.embeddings.position_ids', 'electra.encoder.layer.23.attention.self.value.bias', 'electra.encoder.layer.7.attention.output.LayerNorm.bias', 'electra.encoder.layer.21.attention.self.value.bias', 'electra.encoder.layer.6.attention.self.key.weight', 'electra.encoder.layer.16.attention.self.value.bias', 'electra.encoder.layer.18.output.dense.weight', 'electra.encoder.layer.19.attention.output.LayerNorm.bias', 'electra.encoder.layer.17.attention.self.key.bias', 'electra.encoder.layer.15.output.dense.bias', 'electra.encoder.layer.22.attention.self.value.bias', 'electra.encoder.layer.22.intermediate.dense.bias', 'electra.encoder.layer.5.attention.self.key.weight', 'electra.encoder.layer.9.attention.self.key.bias', 'electra.encoder.layer.14.output.dense.weight', 'electra.encoder.layer.18.attention.self.key.bias', 'electra.encoder.layer.13.intermediate.dense.bias', 'electra.encoder.layer.15.attention.self.query.bias', 'electra.encoder.layer.8.attention.output.LayerNorm.weight', 'electra.encoder.layer.15.attention.self.value.bias', 'electra.embeddings.LayerNorm.bias', 'electra.encoder.layer.17.attention.output.dense.bias', 'electra.encoder.layer.18.attention.output.dense.weight', 'electra.encoder.layer.20.output.LayerNorm.bias', 'electra.encoder.layer.6.attention.output.dense.bias', 'electra.encoder.layer.9.attention.self.query.weight', 'electra.encoder.layer.3.intermediate.dense.bias', 'electra.encoder.layer.16.attention.self.key.weight', 'electra.encoder.layer.23.attention.self.query.weight', 'electra.encoder.layer.10.intermediate.dense.weight', 'electra.encoder.layer.15.intermediate.dense.bias', 'electra.encoder.layer.6.output.dense.bias', 'electra.encoder.layer.23.attention.self.query.bias', 'electra.encoder.layer.20.attention.self.query.bias', 'electra.encoder.layer.1.intermediate.dense.bias', 'electra.encoder.layer.4.intermediate.dense.bias', 'electra.encoder.layer.4.attention.self.query.bias', 'electra.encoder.layer.5.output.dense.bias', 'electra.encoder.layer.3.attention.self.value.bias', 'electra.encoder.layer.13.intermediate.dense.weight', 'electra.encoder.layer.21.attention.self.query.weight', 'electra.encoder.layer.8.attention.self.key.weight', 'electra.encoder.layer.7.attention.self.query.weight', 'electra.encoder.layer.23.intermediate.dense.weight', 'electra.encoder.layer.6.attention.self.value.bias', 'electra.encoder.layer.0.intermediate.dense.weight', 'electra.encoder.layer.14.attention.self.query.weight', 'electra.encoder.layer.2.attention.self.query.bias', 'electra.encoder.layer.3.attention.self.query.weight', 'electra.encoder.layer.7.attention.self.key.bias', 'electra.encoder.layer.8.attention.self.query.weight', 'electra.encoder.layer.12.attention.output.dense.bias', 'electra.encoder.layer.6.attention.output.LayerNorm.weight', 'electra.encoder.layer.0.output.LayerNorm.bias', 'electra.encoder.layer.23.attention.output.dense.bias', 'electra.encoder.layer.20.attention.self.key.bias', 'electra.encoder.layer.5.attention.output.dense.bias', 'electra.encoder.layer.17.attention.output.dense.weight', 'electra.encoder.layer.5.intermediate.dense.bias', 'electra.encoder.layer.17.attention.self.query.bias', 'electra.encoder.layer.1.output.dense.bias', 'electra.encoder.layer.17.attention.self.key.weight', 'electra.encoder.layer.23.attention.self.value.weight', 'electra.embeddings.word_embeddings.weight', 'electra.encoder.layer.8.attention.output.dense.bias', 'electra.encoder.layer.7.intermediate.dense.weight', 'electra.encoder.layer.12.attention.self.key.weight', 'electra.encoder.layer.5.output.dense.weight', 'electra.encoder.layer.16.intermediate.dense.weight', 'electra.encoder.layer.13.attention.self.key.weight', 'electra.encoder.layer.0.intermediate.dense.bias', 'electra.encoder.layer.12.output.dense.weight', 'electra.encoder.layer.9.attention.self.key.weight', 'electra.encoder.layer.19.output.LayerNorm.bias', 'electra.encoder.layer.22.output.LayerNorm.weight', 'electra.encoder.layer.2.attention.self.value.bias', 'electra.encoder.layer.10.attention.self.query.bias', 'electra.encoder.layer.10.attention.output.dense.bias', 'classifier.weight', 'electra.encoder.layer.13.attention.output.LayerNorm.weight', 'electra.encoder.layer.14.attention.self.key.bias', 'electra.encoder.layer.16.attention.output.LayerNorm.weight', 'electra.encoder.layer.12.output.LayerNorm.bias', 'electra.encoder.layer.5.attention.self.key.bias', 'electra.encoder.layer.4.attention.self.value.weight', 'electra.encoder.layer.5.attention.self.query.bias', 'electra.encoder.layer.23.attention.output.LayerNorm.bias', 'electra.encoder.layer.20.attention.output.LayerNorm.weight', 'electra.encoder.layer.21.output.dense.bias', 'electra.encoder.layer.17.intermediate.dense.bias', 'electra.encoder.layer.0.attention.self.query.bias', 'electra.encoder.layer.6.attention.self.key.bias', 'electra.encoder.layer.19.attention.self.key.weight', 'electra.encoder.layer.7.attention.output.dense.weight', 'electra.encoder.layer.8.output.LayerNorm.bias', 'electra.encoder.layer.20.attention.output.dense.weight', 'electra.encoder.layer.5.attention.self.value.weight', 'electra.encoder.layer.12.attention.self.value.bias', 'electra.encoder.layer.19.attention.output.LayerNorm.weight', 'electra.encoder.layer.7.output.dense.weight', 'electra.encoder.layer.11.output.LayerNorm.weight', 'electra.encoder.layer.18.output.dense.bias', 'electra.encoder.layer.3.output.dense.bias', 'electra.encoder.layer.1.attention.self.value.weight', 'electra.encoder.layer.20.intermediate.dense.bias', 'electra.encoder.layer.3.attention.self.key.bias', 'electra.encoder.layer.23.attention.self.key.weight', 'electra.encoder.layer.9.attention.output.LayerNorm.bias', 'electra.encoder.layer.1.attention.output.dense.bias', 'electra.encoder.layer.1.attention.self.value.bias', 'electra.encoder.layer.19.attention.self.value.bias', 'electra.encoder.layer.2.attention.output.dense.bias', 'electra.encoder.layer.0.attention.output.dense.bias', 'electra.encoder.layer.12.intermediate.dense.weight', 'electra.encoder.layer.12.attention.output.dense.weight', 'electra.encoder.layer.3.attention.output.LayerNorm.weight', 'electra.encoder.layer.11.output.dense.weight', 'electra.encoder.layer.8.attention.output.dense.weight', 'electra.encoder.layer.9.output.LayerNorm.bias', 'electra.encoder.layer.14.attention.self.value.bias', 'electra.encoder.layer.2.attention.output.LayerNorm.bias', 'electra.embeddings.LayerNorm.weight', 'electra.encoder.layer.19.attention.output.dense.bias', 'electra.encoder.layer.11.attention.output.LayerNorm.bias', 'electra.encoder.layer.14.attention.output.dense.weight', 'electra.encoder.layer.15.attention.self.key.bias', 'electra.encoder.layer.3.attention.self.key.weight', 'electra.encoder.layer.17.attention.output.LayerNorm.weight', 'electra.encoder.layer.9.output.dense.bias', 'electra.encoder.layer.15.attention.output.LayerNorm.weight', 'electra.encoder.layer.0.output.dense.weight', 'electra.encoder.layer.11.attention.self.value.bias', 'electra.encoder.layer.10.attention.self.value.bias', 'electra.encoder.layer.3.output.LayerNorm.bias', 'electra.encoder.layer.2.attention.output.dense.weight', 'electra.encoder.layer.0.attention.self.query.weight', 'electra.encoder.layer.15.attention.self.query.weight', 'electra.encoder.layer.14.intermediate.dense.weight', 'electra.encoder.layer.5.output.LayerNorm.weight', 'electra.encoder.layer.17.output.LayerNorm.bias', 'electra.encoder.layer.2.output.LayerNorm.weight', 'electra.encoder.layer.14.attention.self.value.weight', 'electra.encoder.layer.4.attention.self.value.bias', 'electra.encoder.layer.11.attention.self.value.weight', 'electra.encoder.layer.13.attention.output.LayerNorm.bias', 'electra.encoder.layer.10.attention.self.key.bias', 'electra.encoder.layer.13.output.LayerNorm.weight', 'electra.encoder.layer.14.attention.output.dense.bias', 'electra.encoder.layer.17.attention.self.value.weight', 'electra.encoder.layer.16.attention.self.key.bias', 'electra.encoder.layer.17.output.dense.weight', 'electra.encoder.layer.23.intermediate.dense.bias', 'electra.encoder.layer.2.attention.self.query.weight', 'electra.encoder.layer.6.attention.self.query.weight', 'electra.encoder.layer.4.output.LayerNorm.bias', 'electra.encoder.layer.0.attention.self.value.weight', 'electra.encoder.layer.7.attention.output.dense.bias', 'electra.encoder.layer.19.attention.output.dense.weight', 'electra.encoder.layer.17.attention.self.query.weight', 'electra.encoder.layer.10.output.dense.weight', 'electra.encoder.layer.8.attention.self.query.bias', 'electra.encoder.layer.18.attention.self.query.weight', 'electra.encoder.layer.18.attention.output.LayerNorm.bias', 'electra.encoder.layer.0.attention.self.key.bias', 'electra.encoder.layer.6.attention.output.dense.weight', 'electra.encoder.layer.22.output.dense.bias', 'electra.encoder.layer.6.attention.output.LayerNorm.bias', 'electra.encoder.layer.9.attention.output.LayerNorm.weight', 'electra.encoder.layer.14.output.dense.bias', 'electra.encoder.layer.7.attention.output.LayerNorm.weight', 'electra.encoder.layer.20.intermediate.dense.weight', 'electra.encoder.layer.7.output.dense.bias', 'electra.encoder.layer.16.attention.self.query.bias', 'electra.encoder.layer.1.output.LayerNorm.bias', 'electra.encoder.layer.11.attention.self.key.weight', 'electra.encoder.layer.8.attention.output.LayerNorm.bias', 'electra.encoder.layer.4.attention.self.key.weight', 'electra.encoder.layer.21.attention.self.value.weight', 'electra.encoder.layer.22.attention.output.dense.bias', 'electra.encoder.layer.14.output.LayerNorm.weight', 'electra.encoder.layer.11.intermediate.dense.bias', 'electra.encoder.layer.1.attention.output.LayerNorm.bias', 'electra.encoder.layer.18.output.LayerNorm.weight', 'electra.encoder.layer.12.intermediate.dense.bias', 'electra.encoder.layer.17.output.dense.bias', 'electra.encoder.layer.5.attention.self.query.weight', 'electra.encoder.layer.0.output.dense.bias', 'electra.encoder.layer.9.intermediate.dense.bias', 'electra.encoder.layer.10.attention.self.value.weight', 'electra.encoder.layer.22.attention.self.key.weight', 'electra.encoder.layer.0.output.LayerNorm.weight', 'electra.encoder.layer.9.output.LayerNorm.weight', 'electra.encoder.layer.17.attention.self.value.bias', 'electra.encoder.layer.13.attention.self.value.bias', 'electra.encoder.layer.15.intermediate.dense.weight', 'electra.encoder.layer.18.intermediate.dense.bias', 'electra.encoder.layer.3.attention.output.dense.bias', 'electra.encoder.layer.12.output.LayerNorm.weight', 'electra.encoder.layer.22.attention.output.LayerNorm.weight', 'electra.encoder.layer.10.attention.self.key.weight', 'electra.encoder.layer.8.attention.self.key.bias', 'electra.encoder.layer.4.output.dense.weight', 'electra.encoder.layer.2.attention.self.value.weight', 'electra.encoder.layer.16.output.dense.weight', 'electra.encoder.layer.3.attention.output.LayerNorm.bias', 'electra.encoder.layer.14.attention.self.query.bias', 'electra.encoder.layer.7.output.LayerNorm.bias', 'electra.encoder.layer.4.attention.output.LayerNorm.bias', 'electra.encoder.layer.14.attention.output.LayerNorm.weight', 'electra.encoder.layer.10.output.dense.bias', 'electra.encoder.layer.6.output.LayerNorm.bias', 'electra.encoder.layer.8.attention.self.value.bias', 'electra.encoder.layer.13.attention.output.dense.weight', 'electra.encoder.layer.0.attention.self.key.weight', 'electra.encoder.layer.11.attention.output.dense.bias', 'electra.encoder.layer.22.intermediate.dense.weight', 'electra.encoder.layer.12.attention.output.LayerNorm.bias', 'electra.encoder.layer.2.intermediate.dense.bias', 'electra.encoder.layer.8.output.dense.weight', 'electra.encoder.layer.10.attention.output.dense.weight', 'electra.encoder.layer.19.attention.self.value.weight', 'electra.encoder.layer.10.attention.output.LayerNorm.bias', 'electra.encoder.layer.16.attention.output.LayerNorm.bias', 'electra.encoder.layer.11.attention.output.dense.weight', 'electra.encoder.layer.12.attention.self.query.bias', 'electra.encoder.layer.21.attention.self.query.bias', 'electra.encoder.layer.22.attention.output.dense.weight', 'electra.encoder.layer.1.output.dense.weight', 'electra.encoder.layer.16.output.LayerNorm.bias', 'electra.encoder.layer.5.output.LayerNorm.bias', 'electra.encoder.layer.16.attention.self.query.weight', 'electra.encoder.layer.11.attention.self.query.weight', 'electra.encoder.layer.4.output.LayerNorm.weight', 'electra.encoder.layer.21.intermediate.dense.weight', 'electra.encoder.layer.9.output.dense.weight', 'electra.encoder.layer.21.output.dense.weight', 'electra.encoder.layer.0.attention.output.LayerNorm.bias', 'electra.encoder.layer.13.attention.self.key.bias', 'electra.encoder.layer.10.attention.self.query.weight', 'electra.encoder.layer.18.intermediate.dense.weight', 'electra.encoder.layer.4.intermediate.dense.weight', 'electra.encoder.layer.15.output.LayerNorm.weight', 'electra.encoder.layer.18.attention.output.LayerNorm.weight', 'electra.encoder.layer.5.attention.self.value.bias', 'electra.encoder.layer.5.attention.output.LayerNorm.bias', 'electra.encoder.layer.16.output.LayerNorm.weight', 'electra.encoder.layer.4.attention.self.key.bias', 'electra.encoder.layer.2.output.dense.weight', 'electra.encoder.layer.3.attention.self.query.bias', 'electra.encoder.layer.12.attention.self.key.bias', 'electra.encoder.layer.21.output.LayerNorm.bias', 'electra.encoder.layer.4.attention.output.dense.weight', 'electra.encoder.layer.3.output.dense.weight', 'electra.encoder.layer.21.attention.output.dense.weight', 'electra.encoder.layer.0.attention.output.dense.weight', 'electra.encoder.layer.9.attention.self.value.weight', 'electra.encoder.layer.11.attention.self.key.bias', 'electra.encoder.layer.21.attention.output.LayerNorm.bias', 'electra.encoder.layer.21.attention.output.dense.bias', 'electra.encoder.layer.14.attention.output.LayerNorm.bias', 'electra.encoder.layer.23.attention.self.key.bias', 'electra.encoder.layer.9.attention.self.query.bias', 'electra.encoder.layer.19.attention.self.query.bias', 'electra.encoder.layer.20.attention.self.query.weight', 'electra.encoder.layer.7.attention.self.query.bias', 'electra.encoder.layer.1.attention.self.query.bias', 'electra.encoder.layer.20.output.LayerNorm.weight', 'electra.encoder.layer.12.attention.output.LayerNorm.weight', 'electra.encoder.layer.2.output.LayerNorm.bias', 'electra.encoder.layer.21.output.LayerNorm.weight', 'electra.encoder.layer.20.output.dense.weight', 'electra.encoder.layer.13.output.LayerNorm.bias', 'classifier.bias', 'electra.encoder.layer.13.attention.output.dense.bias', 'electra.encoder.layer.2.attention.self.key.bias', 'electra.encoder.layer.13.output.dense.weight', 'electra.encoder.layer.18.attention.self.value.weight', 'electra.embeddings.position_embeddings.weight', 'electra.encoder.layer.19.intermediate.dense.weight', 'electra.encoder.layer.4.attention.self.query.weight', 'electra.encoder.layer.6.attention.self.query.bias', 'electra.encoder.layer.22.output.dense.weight', 'electra.encoder.layer.21.attention.self.key.bias', 'electra.encoder.layer.18.attention.output.dense.bias', 'electra.encoder.layer.0.attention.self.value.bias', 'electra.encoder.layer.9.attention.output.dense.weight', 'electra.encoder.layer.16.attention.output.dense.bias', 'electra.encoder.layer.15.output.LayerNorm.bias', 'electra.encoder.layer.23.output.dense.bias', 'electra.encoder.layer.19.output.dense.bias', 'electra.encoder.layer.9.attention.self.value.bias', 'electra.encoder.layer.18.attention.self.value.bias', 'electra.encoder.layer.15.attention.output.dense.bias', 'electra.encoder.layer.15.attention.output.LayerNorm.bias', 'electra.encoder.layer.4.attention.output.LayerNorm.weight', 'electra.encoder.layer.2.output.dense.bias', 'electra.encoder.layer.20.attention.output.dense.bias', 'electra.encoder.layer.7.attention.self.key.weight', 'electra.encoder.layer.22.attention.self.value.weight', 'electra.encoder.layer.1.intermediate.dense.weight', 'electra.encoder.layer.21.attention.output.LayerNorm.weight', 'electra.encoder.layer.3.intermediate.dense.weight', 'electra.encoder.layer.8.attention.self.value.weight', 'electra.encoder.layer.6.output.LayerNorm.weight', 'electra.encoder.layer.11.attention.output.LayerNorm.weight', 'electra.encoder.layer.15.attention.self.key.weight', 'electra.encoder.layer.4.attention.output.dense.bias', 'electra.encoder.layer.18.attention.self.query.bias', 'electra.encoder.layer.7.attention.self.value.weight', 'electra.encoder.layer.8.intermediate.dense.bias', 'electra.encoder.layer.20.attention.self.value.bias', 'electra.encoder.layer.14.output.LayerNorm.bias', 'electra.encoder.layer.11.output.LayerNorm.bias', 'electra.encoder.layer.18.output.LayerNorm.bias', 'electra.encoder.layer.23.output.LayerNorm.bias', 'electra.encoder.layer.22.attention.self.query.bias', 'electra.encoder.layer.19.output.dense.weight', 'electra.encoder.layer.23.attention.output.dense.weight', 'electra.encoder.layer.7.attention.self.value.bias', 'electra.encoder.layer.19.attention.self.query.weight', 'electra.encoder.layer.20.output.dense.bias', 'electra.encoder.layer.12.attention.self.query.weight', 'electra.encoder.layer.7.output.LayerNorm.weight', 'electra.encoder.layer.16.intermediate.dense.bias', 'electra.encoder.layer.16.output.dense.bias', 'electra.encoder.layer.8.output.dense.bias', 'electra.encoder.layer.16.attention.output.dense.weight', 'electra.encoder.layer.23.output.LayerNorm.weight', 'electra.encoder.layer.15.attention.self.value.weight', 'electra.encoder.layer.22.attention.self.query.weight', 'electra.encoder.layer.5.intermediate.dense.weight', 'electra.encoder.layer.8.output.LayerNorm.weight', 'electra.embeddings.token_type_embeddings.weight', 'electra.encoder.layer.14.attention.self.key.weight', 'electra.encoder.layer.5.attention.output.LayerNorm.weight', 'electra.encoder.layer.3.output.LayerNorm.weight', 'electra.encoder.layer.3.attention.output.dense.weight', 'electra.encoder.layer.20.attention.self.value.weight', 'electra.encoder.layer.21.attention.self.key.weight', 'electra.encoder.layer.10.output.LayerNorm.bias', 'electra.encoder.layer.11.attention.self.query.bias', 'electra.encoder.layer.21.intermediate.dense.bias', 'electra.encoder.layer.16.attention.self.value.weight', 'electra.encoder.layer.4.output.dense.bias', 'electra.encoder.layer.0.attention.output.LayerNorm.weight', 'electra.encoder.layer.22.output.LayerNorm.bias', 'electra.encoder.layer.9.intermediate.dense.weight', 'electra.encoder.layer.17.attention.output.LayerNorm.bias', 'electra.encoder.layer.1.attention.output.LayerNorm.weight', 'electra.encoder.layer.3.attention.self.value.weight', 'electra.encoder.layer.14.intermediate.dense.bias', 'electra.encoder.layer.18.attention.self.key.weight', 'electra.encoder.layer.8.intermediate.dense.weight', 'electra.encoder.layer.6.output.dense.weight', 'electra.encoder.layer.2.attention.self.key.weight', 'electra.encoder.layer.10.intermediate.dense.bias', 'electra.encoder.layer.17.intermediate.dense.weight', 'electra.encoder.layer.1.attention.self.query.weight', 'electra.encoder.layer.13.output.dense.bias', 'electra.encoder.layer.1.attention.output.dense.weight', 'electra.encoder.layer.15.output.dense.weight', 'electra.encoder.layer.23.output.dense.weight', 'electra.encoder.layer.13.attention.self.query.weight', 'electra.encoder.layer.2.intermediate.dense.weight', 'electra.encoder.layer.23.attention.output.LayerNorm.weight', 'electra.encoder.layer.12.output.dense.bias', 'electra.encoder.layer.7.intermediate.dense.bias', 'electra.encoder.layer.6.intermediate.dense.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","Some weights of BertModel were not initialized from the model checkpoint at /content/drive/MyDrive/Thesis/BERTOUTPUT/checkpoint-9500/ and are newly initialized: ['encoder.layer.17.intermediate.dense.bias', 'encoder.layer.5.attention.self.query.weight', 'encoder.layer.15.output.dense.bias', 'encoder.layer.14.intermediate.dense.bias', 'encoder.layer.19.output.dense.weight', 'encoder.layer.16.attention.self.key.bias', 'encoder.layer.0.output.LayerNorm.bias', 'encoder.layer.2.intermediate.dense.weight', 'encoder.layer.4.attention.self.key.weight', 'encoder.layer.12.attention.self.key.weight', 'encoder.layer.2.attention.output.LayerNorm.bias', 'encoder.layer.14.output.dense.weight', 'encoder.layer.2.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.key.bias', 'encoder.layer.19.attention.output.dense.bias', 'encoder.layer.7.output.dense.weight', 'encoder.layer.18.attention.output.dense.weight', 'encoder.layer.9.intermediate.dense.bias', 'encoder.layer.5.attention.self.key.weight', 'encoder.layer.6.intermediate.dense.bias', 'encoder.layer.3.intermediate.dense.bias', 'encoder.layer.7.attention.self.value.weight', 'encoder.layer.13.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.bias', 'encoder.layer.22.output.dense.bias', 'encoder.layer.0.attention.output.LayerNorm.weight', 'embeddings.LayerNorm.weight', 'encoder.layer.8.attention.output.LayerNorm.weight', 'encoder.layer.5.intermediate.dense.bias', 'encoder.layer.7.output.LayerNorm.weight', 'encoder.layer.20.output.dense.weight', 'encoder.layer.10.attention.output.dense.weight', 'encoder.layer.2.attention.self.value.weight', 'encoder.layer.1.attention.output.LayerNorm.weight', 'encoder.layer.8.attention.self.value.weight', 'encoder.layer.21.intermediate.dense.bias', 'encoder.layer.2.attention.self.query.bias', 'encoder.layer.3.intermediate.dense.weight', 'encoder.layer.8.output.dense.weight', 'encoder.layer.22.output.LayerNorm.weight', 'encoder.layer.6.attention.self.value.weight', 'encoder.layer.16.attention.output.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.weight', 'encoder.layer.1.attention.self.query.bias', 'encoder.layer.8.intermediate.dense.weight', 'encoder.layer.1.attention.output.dense.weight', 'encoder.layer.3.attention.self.value.bias', 'encoder.layer.1.attention.self.value.weight', 'encoder.layer.18.intermediate.dense.weight', 'encoder.layer.12.attention.output.dense.bias', 'encoder.layer.15.attention.self.value.bias', 'encoder.layer.20.attention.output.dense.weight', 'encoder.layer.18.intermediate.dense.bias', 'encoder.layer.9.output.LayerNorm.bias', 'encoder.layer.4.output.dense.weight', 'encoder.layer.9.output.LayerNorm.weight', 'encoder.layer.5.output.dense.bias', 'encoder.layer.4.attention.output.dense.weight', 'encoder.layer.16.output.dense.bias', 'encoder.layer.18.output.LayerNorm.weight', 'encoder.layer.12.attention.output.LayerNorm.weight', 'encoder.layer.22.attention.self.value.weight', 'encoder.layer.10.attention.output.LayerNorm.bias', 'encoder.layer.9.output.dense.weight', 'encoder.layer.2.attention.self.query.weight', 'encoder.layer.21.attention.self.query.weight', 'encoder.layer.5.output.dense.weight', 'encoder.layer.15.attention.output.dense.weight', 'encoder.layer.3.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.query.weight', 'encoder.layer.4.attention.output.LayerNorm.weight', 'encoder.layer.12.attention.self.key.bias', 'encoder.layer.23.output.dense.bias', 'encoder.layer.9.attention.self.key.bias', 'encoder.layer.12.attention.output.LayerNorm.bias', 'encoder.layer.19.intermediate.dense.weight', 'encoder.layer.5.attention.output.dense.weight', 'encoder.layer.23.output.dense.weight', 'encoder.layer.23.attention.self.value.weight', 'encoder.layer.7.intermediate.dense.weight', 'encoder.layer.10.output.dense.bias', 'encoder.layer.12.output.dense.bias', 'encoder.layer.4.attention.self.value.bias', 'encoder.layer.17.attention.output.LayerNorm.weight', 'encoder.layer.19.output.LayerNorm.bias', 'encoder.layer.15.intermediate.dense.bias', 'encoder.layer.6.output.dense.weight', 'encoder.layer.8.output.dense.bias', 'encoder.layer.1.attention.self.value.bias', 'encoder.layer.16.attention.self.value.weight', 'encoder.layer.6.attention.self.query.bias', 'encoder.layer.17.attention.self.query.bias', 'encoder.layer.15.output.LayerNorm.weight', 'encoder.layer.1.intermediate.dense.weight', 'encoder.layer.11.attention.self.value.weight', 'encoder.layer.2.attention.self.key.weight', 'encoder.layer.8.attention.output.LayerNorm.bias', 'encoder.layer.16.output.dense.weight', 'encoder.layer.3.output.dense.weight', 'encoder.layer.16.output.LayerNorm.bias', 'encoder.layer.9.attention.self.value.bias', 'encoder.layer.20.attention.output.LayerNorm.bias', 'encoder.layer.15.attention.self.key.weight', 'encoder.layer.17.attention.self.value.bias', 'encoder.layer.20.intermediate.dense.weight', 'encoder.layer.18.attention.output.LayerNorm.bias', 'encoder.layer.21.attention.output.dense.bias', 'encoder.layer.21.attention.output.dense.weight', 'encoder.layer.8.intermediate.dense.bias', 'encoder.layer.19.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.self.query.bias', 'encoder.layer.13.attention.self.query.weight', 'encoder.layer.13.attention.output.dense.weight', 'encoder.layer.6.attention.output.LayerNorm.bias', 'encoder.layer.23.attention.self.value.bias', 'encoder.layer.4.attention.output.dense.bias', 'encoder.layer.19.attention.output.dense.weight', 'encoder.layer.11.attention.self.value.bias', 'encoder.layer.0.attention.output.LayerNorm.bias', 'encoder.layer.18.attention.self.value.bias', 'encoder.layer.18.attention.self.query.weight', 'encoder.layer.8.attention.self.query.bias', 'encoder.layer.23.intermediate.dense.weight', 'encoder.layer.0.attention.output.dense.weight', 'encoder.layer.15.attention.self.key.bias', 'encoder.layer.22.attention.self.key.weight', 'encoder.layer.7.attention.self.key.bias', 'encoder.layer.20.output.LayerNorm.bias', 'encoder.layer.19.attention.self.value.bias', 'encoder.layer.10.intermediate.dense.bias', 'encoder.layer.22.intermediate.dense.weight', 'embeddings.token_type_embeddings.weight', 'encoder.layer.18.attention.self.value.weight', 'encoder.layer.6.attention.output.dense.weight', 'encoder.layer.23.attention.self.key.weight', 'encoder.layer.14.attention.output.LayerNorm.bias', 'encoder.layer.14.attention.output.dense.bias', 'encoder.layer.20.attention.self.key.bias', 'encoder.layer.10.attention.self.key.bias', 'encoder.layer.3.attention.self.query.bias', 'encoder.layer.16.output.LayerNorm.weight', 'encoder.layer.19.attention.self.query.bias', 'encoder.layer.10.attention.self.query.weight', 'encoder.layer.6.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.output.LayerNorm.weight', 'encoder.layer.16.attention.self.value.bias', 'encoder.layer.21.output.dense.bias', 'encoder.layer.2.output.dense.weight', 'encoder.layer.8.attention.output.dense.bias', 'encoder.layer.3.attention.self.key.bias', 'encoder.layer.18.output.dense.weight', 'encoder.layer.12.output.LayerNorm.bias', 'encoder.layer.0.output.dense.bias', 'encoder.layer.3.output.LayerNorm.weight', 'encoder.layer.13.attention.output.LayerNorm.bias', 'encoder.layer.14.output.LayerNorm.weight', 'encoder.layer.3.output.dense.bias', 'encoder.layer.16.attention.output.dense.bias', 'encoder.layer.5.attention.output.dense.bias', 'encoder.layer.14.intermediate.dense.weight', 'encoder.layer.15.output.LayerNorm.bias', 'encoder.layer.4.intermediate.dense.weight', 'encoder.layer.23.attention.self.key.bias', 'encoder.layer.7.attention.self.key.weight', 'encoder.layer.2.intermediate.dense.bias', 'encoder.layer.17.attention.self.query.weight', 'encoder.layer.20.attention.self.value.weight', 'encoder.layer.18.attention.output.dense.bias', 'encoder.layer.13.output.LayerNorm.bias', 'encoder.layer.22.intermediate.dense.bias', 'encoder.layer.10.attention.self.key.weight', 'encoder.layer.13.output.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.query.bias', 'encoder.layer.0.attention.self.key.weight', 'encoder.layer.6.output.LayerNorm.weight', 'encoder.layer.23.attention.output.dense.bias', 'pooler.dense.bias', 'encoder.layer.18.output.dense.bias', 'encoder.layer.8.attention.self.value.bias', 'encoder.layer.15.attention.self.value.weight', 'encoder.layer.2.output.LayerNorm.weight', 'encoder.layer.19.attention.self.query.weight', 'encoder.layer.20.attention.self.key.weight', 'encoder.layer.5.attention.self.query.bias', 'encoder.layer.17.output.LayerNorm.bias', 'encoder.layer.16.attention.output.LayerNorm.weight', 'encoder.layer.9.attention.output.dense.bias', 'encoder.layer.16.intermediate.dense.weight', 'encoder.layer.23.intermediate.dense.bias', 'encoder.layer.13.attention.self.value.bias', 'encoder.layer.13.output.LayerNorm.weight', 'encoder.layer.14.output.LayerNorm.bias', 'encoder.layer.15.attention.output.LayerNorm.bias', 'encoder.layer.7.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.value.weight', 'encoder.layer.6.intermediate.dense.weight', 'encoder.layer.13.attention.self.query.bias', 'encoder.layer.12.attention.self.query.bias', 'encoder.layer.4.attention.self.key.bias', 'encoder.layer.4.intermediate.dense.bias', 'encoder.layer.10.intermediate.dense.weight', 'encoder.layer.11.attention.output.dense.bias', 'encoder.layer.14.attention.self.value.bias', 'encoder.layer.1.attention.self.key.bias', 'encoder.layer.2.output.dense.bias', 'encoder.layer.11.attention.self.key.bias', 'encoder.layer.15.intermediate.dense.weight', 'encoder.layer.13.attention.self.value.weight', 'encoder.layer.15.output.dense.weight', 'encoder.layer.9.attention.self.key.weight', 'encoder.layer.8.attention.self.key.bias', 'encoder.layer.5.output.LayerNorm.weight', 'encoder.layer.16.intermediate.dense.bias', 'encoder.layer.11.intermediate.dense.weight', 'encoder.layer.9.attention.output.dense.weight', 'encoder.layer.17.output.LayerNorm.weight', 'encoder.layer.15.attention.self.query.bias', 'encoder.layer.11.output.dense.weight', 'encoder.layer.9.output.dense.bias', 'encoder.layer.21.output.dense.weight', 'encoder.layer.11.attention.self.key.weight', 'encoder.layer.5.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.self.query.bias', 'encoder.layer.0.attention.self.value.bias', 'encoder.layer.4.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.weight', 'encoder.layer.12.attention.self.query.weight', 'encoder.layer.9.intermediate.dense.weight', 'encoder.layer.21.attention.self.key.weight', 'encoder.layer.17.intermediate.dense.weight', 'encoder.layer.1.intermediate.dense.bias', 'encoder.layer.11.output.dense.bias', 'encoder.layer.3.attention.output.dense.weight', 'encoder.layer.0.attention.output.dense.bias', 'encoder.layer.22.attention.self.query.bias', 'encoder.layer.5.attention.self.key.bias', 'encoder.layer.13.intermediate.dense.bias', 'encoder.layer.20.attention.self.value.bias', 'encoder.layer.4.attention.self.query.bias', 'encoder.layer.20.attention.output.dense.bias', 'encoder.layer.0.intermediate.dense.bias', 'encoder.layer.10.attention.output.dense.bias', 'encoder.layer.1.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.bias', 'encoder.layer.20.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.output.dense.bias', 'encoder.layer.22.output.dense.weight', 'encoder.layer.17.output.dense.weight', 'encoder.layer.20.attention.self.query.weight', 'encoder.layer.2.attention.self.value.bias', 'encoder.layer.6.attention.output.dense.bias', 'encoder.layer.7.attention.output.LayerNorm.weight', 'encoder.layer.23.attention.output.LayerNorm.bias', 'encoder.layer.21.output.LayerNorm.weight', 'encoder.layer.17.output.dense.bias', 'encoder.layer.21.attention.self.key.bias', 'encoder.layer.2.output.LayerNorm.bias', 'encoder.layer.11.attention.output.dense.weight', 'encoder.layer.17.attention.output.LayerNorm.bias', 'encoder.layer.0.output.LayerNorm.weight', 'encoder.layer.15.attention.output.LayerNorm.weight', 'encoder.layer.1.output.dense.weight', 'encoder.layer.21.output.LayerNorm.bias', 'encoder.layer.0.intermediate.dense.weight', 'encoder.layer.11.attention.self.query.weight', 'encoder.layer.1.attention.self.query.weight', 'encoder.layer.23.output.LayerNorm.weight', 'encoder.layer.16.attention.self.key.weight', 'encoder.layer.12.output.dense.weight', 'encoder.layer.18.output.LayerNorm.bias', 'encoder.layer.20.output.LayerNorm.weight', 'encoder.layer.18.attention.self.key.bias', 'encoder.layer.1.attention.output.LayerNorm.bias', 'encoder.layer.17.attention.self.key.weight', 'encoder.layer.12.intermediate.dense.bias', 'encoder.layer.21.attention.output.LayerNorm.bias', 'encoder.layer.6.output.LayerNorm.bias', 'encoder.layer.12.attention.self.value.bias', 'encoder.layer.0.attention.self.query.weight', 'encoder.layer.19.attention.output.LayerNorm.weight', 'encoder.layer.4.attention.output.LayerNorm.bias', 'encoder.layer.0.attention.self.key.bias', 'encoder.layer.6.output.dense.bias', 'encoder.layer.23.attention.output.dense.weight', 'encoder.layer.13.intermediate.dense.weight', 'encoder.layer.12.intermediate.dense.weight', 'encoder.layer.7.output.LayerNorm.bias', 'encoder.layer.12.attention.output.dense.weight', 'encoder.layer.14.output.dense.bias', 'encoder.layer.11.attention.self.query.bias', 'encoder.layer.22.attention.self.query.weight', 'encoder.layer.22.attention.output.dense.weight', 'encoder.layer.14.attention.self.query.weight', 'encoder.layer.4.attention.self.query.weight', 'encoder.layer.16.attention.output.LayerNorm.bias', 'embeddings.position_embeddings.weight', 'encoder.layer.4.output.LayerNorm.bias', 'encoder.layer.3.output.LayerNorm.bias', 'encoder.layer.5.output.LayerNorm.bias', 'encoder.layer.3.attention.output.LayerNorm.weight', 'encoder.layer.7.intermediate.dense.bias', 'encoder.layer.13.attention.self.key.weight', 'encoder.layer.17.attention.output.dense.weight', 'encoder.layer.0.output.dense.weight', 'encoder.layer.8.attention.output.dense.weight', 'encoder.layer.19.intermediate.dense.bias', 'encoder.layer.14.attention.self.key.bias', 'encoder.layer.1.attention.output.dense.bias', 'encoder.layer.4.output.LayerNorm.weight', 'encoder.layer.10.attention.self.query.bias', 'encoder.layer.5.intermediate.dense.weight', 'encoder.layer.14.attention.output.dense.weight', 'encoder.layer.23.attention.output.LayerNorm.weight', 'encoder.layer.17.attention.self.value.weight', 'encoder.layer.3.attention.self.query.weight', 'encoder.layer.23.attention.self.query.weight', 'encoder.layer.1.output.dense.bias', 'encoder.layer.19.attention.self.key.weight', 'encoder.layer.21.attention.self.value.bias', 'pooler.dense.weight', 'encoder.layer.9.attention.self.query.bias', 'encoder.layer.19.output.LayerNorm.weight', 'encoder.layer.16.attention.self.query.weight', 'encoder.layer.14.attention.self.value.weight', 'encoder.layer.14.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.key.weight', 'encoder.layer.20.output.dense.bias', 'encoder.layer.7.attention.self.query.weight', 'encoder.layer.8.attention.self.query.weight', 'encoder.layer.4.output.dense.bias', 'encoder.layer.16.attention.self.query.bias', 'encoder.layer.15.attention.output.dense.bias', 'encoder.layer.22.attention.output.LayerNorm.bias', 'encoder.layer.9.attention.self.query.weight', 'encoder.layer.1.attention.self.key.weight', 'encoder.layer.5.attention.output.LayerNorm.bias', 'encoder.layer.23.output.LayerNorm.bias', 'encoder.layer.17.attention.self.key.bias', 'encoder.layer.22.attention.output.dense.bias', 'encoder.layer.19.attention.self.key.bias', 'encoder.layer.22.output.LayerNorm.bias', 'encoder.layer.11.intermediate.dense.bias', 'encoder.layer.18.attention.self.key.weight', 'encoder.layer.10.attention.self.value.bias', 'encoder.layer.12.output.LayerNorm.weight', 'encoder.layer.14.attention.self.query.bias', 'encoder.layer.9.attention.self.value.weight', 'encoder.layer.2.attention.self.key.bias', 'encoder.layer.13.attention.self.key.bias', 'encoder.layer.6.attention.self.query.weight', 'encoder.layer.7.attention.output.dense.weight', 'encoder.layer.18.attention.self.query.bias', 'encoder.layer.7.attention.self.value.bias', 'encoder.layer.21.attention.self.query.bias', 'encoder.layer.14.attention.self.key.weight', 'encoder.layer.19.output.dense.bias', 'encoder.layer.6.attention.self.value.bias', 'encoder.layer.22.attention.self.value.bias', 'encoder.layer.22.attention.output.LayerNorm.weight', 'embeddings.LayerNorm.bias', 'encoder.layer.12.attention.self.value.weight', 'encoder.layer.10.output.dense.weight', 'encoder.layer.11.output.LayerNorm.weight', 'encoder.layer.21.intermediate.dense.weight', 'encoder.layer.7.output.dense.bias', 'encoder.layer.13.output.dense.weight', 'encoder.layer.5.attention.self.value.bias', 'encoder.layer.17.attention.output.dense.bias', 'encoder.layer.6.attention.self.key.weight', 'encoder.layer.2.attention.output.dense.weight', 'encoder.layer.19.attention.self.value.weight', 'encoder.layer.11.output.LayerNorm.bias', 'encoder.layer.20.attention.self.query.bias', 'encoder.layer.2.attention.output.dense.bias', 'encoder.layer.13.attention.output.LayerNorm.weight', 'encoder.layer.10.attention.self.value.weight', 'encoder.layer.10.output.LayerNorm.bias', 'encoder.layer.21.attention.output.LayerNorm.weight', 'encoder.layer.8.output.LayerNorm.weight', 'encoder.layer.8.attention.self.key.weight', 'encoder.layer.21.attention.self.value.weight', 'encoder.layer.8.output.LayerNorm.bias', 'encoder.layer.11.attention.output.LayerNorm.weight', 'encoder.layer.3.attention.self.value.weight', 'embeddings.word_embeddings.weight', 'encoder.layer.20.intermediate.dense.bias', 'encoder.layer.9.attention.output.LayerNorm.weight', 'encoder.layer.1.output.LayerNorm.weight', 'encoder.layer.7.attention.output.dense.bias', 'encoder.layer.5.attention.self.value.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}]},{"cell_type":"code","source":["from transformers import AutoTokenizer\n","tokenizer = AutoTokenizer.from_pretrained(\"csebuetnlp/banglabert_large\")"],"metadata":{"id":"0okLD3xQpxGN","colab":{"base_uri":"https://localhost:8080/","height":145,"referenced_widgets":["cb8f68a651694a319f70fddb5f73eec7","0267149a4f7744b988c0ff948129fafd","c583e2b3379d4269b30db0489a5614c6","87539224aafa4f949d9b20aee2d83997","240169913a194caea37e6e9a22364a18","80c30aebfb8546c5bc7f36d7cb727c9b","757f2fb5337c4f28a287039a4eaceecb","34948fcba52548d7b737ac3e34341672","c418a8c535754ee883b6ee91d57879df","142401b7059a4edd804fd7dce8ee788a","3b6beea49f8541948a9135f3a5fb8236","662c757466f242ec82d5a374021ec103","bfb3cf69f12b40bda467a6ff699d902e","9c776ce625614f3687ab0f7e236bf00a","cac81c7fb04144398a6f4afac5897314","1b6f053c4a67457fbe1faa0cf688784c","a10d6323d60b47c1b459e19077252979","adcd27c175474542b2b3f199163e0230","5a219d37890543f4a50d7224e4ab96bd","9fea8bca6111489ea9dc1f5c8e22bf30","520c952de9824b18898e35a786cd911e","1278288c122a472d98fea12d59b6fec3","d05d84122d52430d9f81db1b1debc13c","e7a65b695866488bb578e846914e478e","99340238d1034f348cd7d66535bd4737","7f8239b7e38147fbad093e5706d4a27c","8c1704fa5565499694b14b583caf88f9","371eea0763a54251ab30104358485604","7a20335d14c149f799e8bb07077f9e6e","79e07bb9bd4b4eb29d06418c59e88b8d","2fae1da67068483a87c025ee7c68d5fe","2ce80c8d8fab40afa5cd04a8bb33d6f5","c8fc7d3efc3d4665ba95f62828ef35d7","f9d9a15a829e46d282539263aa258d6c","9e5a398c144b4202828e91056a39b091","f1546ac39d904d51adbf9711a7b53f1e","e854a920a3ed4500a0462b663648ffce","4957ce9c848b45f2b74c53737a8a30f3","f5f3c7730cd645d7ad8430655f1c0141","896f323195d34e4f80f5bf45a64d029e","ef4ec114e15d4de8a9f69febf4ed659f","19de8f2a76d744aca014440736c03499","5e7f5f9306504a90872df147ba36283c","a3c9ab89afb0494e81e7247c321c4f9e"]},"executionInfo":{"status":"ok","timestamp":1680534630916,"user_tz":-360,"elapsed":2684,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"6422e557-52e9-413a-f2be-f1b230bf8b96"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/119 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"cb8f68a651694a319f70fddb5f73eec7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/880 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"662c757466f242ec82d5a374021ec103"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/528k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d05d84122d52430d9f81db1b1debc13c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)cial_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9d9a15a829e46d282539263aa258d6c"}},"metadata":{}}]},{"cell_type":"code","source":["def tokenize_function(examples):\n","    return tokenizer(examples[\"tokens\"], padding=\"max_length\", truncation=True, is_split_into_words=True)"],"metadata":{"id":"RYYbGmSNrFDP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["original_sentence = \"আমি কৃতজ্ঞ কারণ আপনি আমার জন্য অনেক কিছু করেছেন।\"\n","fake_sentence = \"আমি হতাশ কারণ কারণ\"\n","fake_sentence = normalize(fake_sentence) # this normalization step is required before tokenizing the text\n","\n","fake_inputs = tokenizer.encode(fake_sentence, return_tensors=\"pt\", padding = \"max_length\", max_length=64)\n","fake_inputs.size()"],"metadata":{"id":"zl6740Jfynro","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680534667337,"user_tz":-360,"elapsed":390,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"5778781f-7ef2-45e1-fde4-7b107e1101b8"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 64])"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["def function(sentence):\n","  \n","  inputs = tokenizer.encode(sentence, return_tensors=\"pt\", padding = \"max_length\", max_length=64)\n","  x = model(inputs)\n","  return x"],"metadata":{"id":"qG7JeA-xQsoC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x = model(fake_inputs)"],"metadata":{"id":"URD7_yIiPb0P"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["x.keys()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ATMoJE0JTlDp","executionInfo":{"status":"ok","timestamp":1680534686782,"user_tz":-360,"elapsed":3,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"fb14468f-ef59-40be-b0cf-7e9c0c684a72"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["odict_keys(['last_hidden_state', 'pooler_output', 'hidden_states'])"]},"metadata":{},"execution_count":10}]},{"cell_type":"code","source":["x[-1][24].size()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"YP1DyQwKPiRw","executionInfo":{"status":"ok","timestamp":1680534688495,"user_tz":-360,"elapsed":3,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"77bb8e9e-fc9f-4f07-c782-c79b22b21986"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Size([1, 64, 1024])"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["x[-1][24]"],"metadata":{"id":"ztENLzqfs-ms","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1680534714178,"user_tz":-360,"elapsed":5,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"33bf000c-0404-4ed0-a619-3bfcb2b0733b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensor([[[-0.3307,  0.5585,  0.8973,  ..., -0.1955,  0.3082, -0.8330],\n","         [-0.4908,  0.8782,  0.8593,  ...,  0.2612, -0.1340, -0.2687],\n","         [-0.6748,  0.6884,  0.4536,  ..., -0.3293,  0.0070, -0.7959],\n","         ...,\n","         [-0.2373,  0.3227,  0.7556,  ...,  0.1866,  0.2783, -0.3301],\n","         [-0.8295,  0.5588,  0.6122,  ...,  0.3623,  0.4980, -0.2209],\n","         [-0.5875,  0.5125,  0.6693,  ...,  0.2300,  0.5320, -0.4920]]],\n","       grad_fn=<NativeLayerNormBackward0>)"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","source":["type(function(\"আমি কৃতজ্ঞ কারণ আপনি\")[-1][24])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-4mVD_rVrYLY","executionInfo":{"status":"ok","timestamp":1680455598021,"user_tz":-360,"elapsed":543,"user":{"displayName":"Niloy Farhan","userId":"08849852492544460038"}},"outputId":"c39a0388-6dcb-4b77-9ec1-561449ed9f9a"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["torch.Tensor"]},"metadata":{},"execution_count":14}]},{"cell_type":"code","source":["pytorch_tensor = torch.zeros(10)\n","np_tensor = pytorch_tensor.numpy()\n","tf_tensor = tf.convert_to_tensor(np_tensor)\n","type(tf_tensor)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xecDaAND7T37","executionInfo":{"status":"ok","timestamp":1680455606558,"user_tz":-360,"elapsed":1074,"user":{"displayName":"Niloy Farhan","userId":"08849852492544460038"}},"outputId":"ccff46be-65f6-475a-932a-72c74e917bf1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensorflow.python.framework.ops.Tensor"]},"metadata":{},"execution_count":15}]},{"cell_type":"code","source":["import pandas as pd"],"metadata":{"id":"7ROEIQ1z9cZ0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(\"/content/trainData2022PP2.csv\", encoding = \"utf-8\")[:10]\n","df.tail()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"dqtPSePbo6b0","executionInfo":{"status":"ok","timestamp":1680455623478,"user_tz":-360,"elapsed":4,"user":{"displayName":"Niloy Farhan","userId":"08849852492544460038"}},"outputId":"09d75aab-82b2-479b-9fc1-8de7de897487"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        Sentence #                                               Word  \\\n","5  Sentence: 10001              পাথরকান্দি লঙ্গাই নদী এর তীরে অবস্থিত   \n","6  Sentence: 10002  শিরোনাম হল একটি স্ট্রিটকার নামক ডিজায়ার এর প্...   \n","7  Sentence: 10003  ব্যবহারকারীরা অনিরাপদভাবে পাসওয়ার্ডগুলি পরিচা...   \n","8  Sentence: 10004  তার তৃতীয় সপ্তাহান্তে চলচ্চিত্রটি ৩৪৫ মিলিয়ন...   \n","9  Sentence: 10005  আক্রমণাত্মক প্রজাতির প্রচলনের বর্তমান সময়টি ১...   \n","\n","                                                 Tag  \n","5             ['O', 'B-LOC', 'I-LOC', 'O', 'O', 'O']  \n","6  ['O', 'O', 'B-CW', 'I-CW', 'I-CW', 'I-CW', 'O'...  \n","7  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n","8  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...  \n","9  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GRP', '...  "],"text/html":["\n","  <div id=\"df-9156b2ce-e1af-43d0-b601-43e266bab42f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence #</th>\n","      <th>Word</th>\n","      <th>Tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>5</th>\n","      <td>Sentence: 10001</td>\n","      <td>পাথরকান্দি লঙ্গাই নদী এর তীরে অবস্থিত</td>\n","      <td>['O', 'B-LOC', 'I-LOC', 'O', 'O', 'O']</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>Sentence: 10002</td>\n","      <td>শিরোনাম হল একটি স্ট্রিটকার নামক ডিজায়ার এর প্...</td>\n","      <td>['O', 'O', 'B-CW', 'I-CW', 'I-CW', 'I-CW', 'O'...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>Sentence: 10003</td>\n","      <td>ব্যবহারকারীরা অনিরাপদভাবে পাসওয়ার্ডগুলি পরিচা...</td>\n","      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>Sentence: 10004</td>\n","      <td>তার তৃতীয় সপ্তাহান্তে চলচ্চিত্রটি ৩৪৫ মিলিয়ন...</td>\n","      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', ...</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>Sentence: 10005</td>\n","      <td>আক্রমণাত্মক প্রজাতির প্রচলনের বর্তমান সময়টি ১...</td>\n","      <td>['O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-GRP', '...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9156b2ce-e1af-43d0-b601-43e266bab42f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-9156b2ce-e1af-43d0-b601-43e266bab42f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-9156b2ce-e1af-43d0-b601-43e266bab42f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":18}]},{"cell_type":"code","source":["d = {'O': 0, 'B-CORP': 1, 'I-CORP': 2, 'B-CW': 3, 'I-CW': 4, 'B-GRP': 5, 'I-GRP': 6, 'B-LOC': 7, 'I-LOC': 8, 'B-PER': 9, 'I-PER': 10, 'B-PROD': 11, 'I-PROD': 12}\n","def label_encoder(x):\n","    x = eval(x)\n","    y = []\n","    for i in x:\n","      y.append(d[i])\n","    return y\n","df['Tag'] = df['Tag'].apply(lambda x: label_encoder(x))\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"2mRwAovwt96b","executionInfo":{"status":"ok","timestamp":1680455638288,"user_tz":-360,"elapsed":556,"user":{"displayName":"Niloy Farhan","userId":"08849852492544460038"}},"outputId":"995b0a4e-bcd9-4cbb-b731-60b055dadbe5"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["        Sentence #                                               Word  \\\n","0      Sentence: 1  ২০১৮ এর সেরা বর্ণানুক্রমিকভাবে তালিকাভুক্ত র‍্...   \n","1     Sentence: 10   সিনেমায় গানটির বৈশিষ্ট্য রয়েছে রাস্তা যাত্রা ।   \n","2    Sentence: 100  করে বাদ্যযন্ত্রের থিম এবং চলচ্চিত্রের জন্য প্র...   \n","3   Sentence: 1000  প্রতিষ্ঠান ২২১১ ইঙ্গিত করে যে আউগুস্তুস পৃথক ক...   \n","4  Sentence: 10000  শো স্টপারে তাদের বেকড আলাস্কা করতে সাড়ে চার ঘ...   \n","\n","                                          Tag  \n","0                 [0, 0, 0, 0, 0, 0, 0, 0, 1]  \n","1                       [0, 0, 0, 0, 3, 4, 0]  \n","2                    [5, 0, 0, 0, 0, 0, 0, 0]  \n","3  [0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0]  \n","4         [0, 0, 0, 11, 12, 0, 0, 0, 0, 0, 0]  "],"text/html":["\n","  <div id=\"df-e2d2e4e8-63cb-402c-8155-57bcadafc769\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence #</th>\n","      <th>Word</th>\n","      <th>Tag</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sentence: 1</td>\n","      <td>২০১৮ এর সেরা বর্ণানুক্রমিকভাবে তালিকাভুক্ত র‍্...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sentence: 10</td>\n","      <td>সিনেমায় গানটির বৈশিষ্ট্য রয়েছে রাস্তা যাত্রা ।</td>\n","      <td>[0, 0, 0, 0, 3, 4, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sentence: 100</td>\n","      <td>করে বাদ্যযন্ত্রের থিম এবং চলচ্চিত্রের জন্য প্র...</td>\n","      <td>[5, 0, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sentence: 1000</td>\n","      <td>প্রতিষ্ঠান ২২১১ ইঙ্গিত করে যে আউগুস্তুস পৃথক ক...</td>\n","      <td>[0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sentence: 10000</td>\n","      <td>শো স্টপারে তাদের বেকড আলাস্কা করতে সাড়ে চার ঘ...</td>\n","      <td>[0, 0, 0, 11, 12, 0, 0, 0, 0, 0, 0]</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e2d2e4e8-63cb-402c-8155-57bcadafc769')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-e2d2e4e8-63cb-402c-8155-57bcadafc769 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-e2d2e4e8-63cb-402c-8155-57bcadafc769');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["# !pip install \"tqdm>=4.9.0\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H-_tNVQYxHhs","executionInfo":{"status":"ok","timestamp":1680454692792,"user_tz":-360,"elapsed":4160,"user":{"displayName":"Niloy Farhan","userId":"08849852492544460038"}},"outputId":"b21a4ada-91c4-421b-8d3b-c578e04b4700"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Requirement already satisfied: tqdm>=4.9.0 in /usr/local/lib/python3.9/dist-packages (4.65.0)\n"]}]},{"cell_type":"code","source":["def word_encoder(x):\n","    # x = function(x)[-1][24]\n","    # x_detached = x.detach()\n","\n","    # # convert detached tensor to NumPy array\n","    # # x_np = x_detached.numpy()\n","\n","    # # convert NumPy array to TensorFlow tensor\n","    # x_tf = tf.convert_to_tensor(x_detached)\n","    return tf.convert_to_tensor(function(x)[-1][24].detach().numpy())\n","    # return x_tf\n","import pandas as pd\n","import numpy as np\n","from tqdm import tqdm\n","tqdm.pandas()\n","df['word_encoded'] = df['Word'].progress_apply(lambda x: word_encoder(x))\n","df.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":223},"id":"vhZqfxElv3Vx","executionInfo":{"status":"ok","timestamp":1680455675535,"user_tz":-360,"elapsed":7335,"user":{"displayName":"Niloy Farhan","userId":"08849852492544460038"}},"outputId":"33c578a6-b885-4bc7-8d5f-c4d81e300f6f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 10/10 [00:07<00:00,  1.30it/s]\n"]},{"output_type":"execute_result","data":{"text/plain":["        Sentence #                                               Word  \\\n","0      Sentence: 1  ২০১৮ এর সেরা বর্ণানুক্রমিকভাবে তালিকাভুক্ত র‍্...   \n","1     Sentence: 10   সিনেমায় গানটির বৈশিষ্ট্য রয়েছে রাস্তা যাত্রা ।   \n","2    Sentence: 100  করে বাদ্যযন্ত্রের থিম এবং চলচ্চিত্রের জন্য প্র...   \n","3   Sentence: 1000  প্রতিষ্ঠান ২২১১ ইঙ্গিত করে যে আউগুস্তুস পৃথক ক...   \n","4  Sentence: 10000  শো স্টপারে তাদের বেকড আলাস্কা করতে সাড়ে চার ঘ...   \n","\n","                                          Tag  \\\n","0                 [0, 0, 0, 0, 0, 0, 0, 0, 1]   \n","1                       [0, 0, 0, 0, 3, 4, 0]   \n","2                    [5, 0, 0, 0, 0, 0, 0, 0]   \n","3  [0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0]   \n","4         [0, 0, 0, 11, 12, 0, 0, 0, 0, 0, 0]   \n","\n","                                        word_encoded  \n","0  Tensor(\"Const_1:0\", shape=(1, 64, 1024), dtype...  \n","1  Tensor(\"Const_2:0\", shape=(1, 64, 1024), dtype...  \n","2  Tensor(\"Const_3:0\", shape=(1, 64, 1024), dtype...  \n","3  Tensor(\"Const_4:0\", shape=(1, 64, 1024), dtype...  \n","4  Tensor(\"Const_5:0\", shape=(1, 64, 1024), dtype...  "],"text/html":["\n","  <div id=\"df-7390f383-da12-4114-a691-31288998ba70\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Sentence #</th>\n","      <th>Word</th>\n","      <th>Tag</th>\n","      <th>word_encoded</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Sentence: 1</td>\n","      <td>২০১৮ এর সেরা বর্ণানুক্রমিকভাবে তালিকাভুক্ত র‍্...</td>\n","      <td>[0, 0, 0, 0, 0, 0, 0, 0, 1]</td>\n","      <td>Tensor(\"Const_1:0\", shape=(1, 64, 1024), dtype...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Sentence: 10</td>\n","      <td>সিনেমায় গানটির বৈশিষ্ট্য রয়েছে রাস্তা যাত্রা ।</td>\n","      <td>[0, 0, 0, 0, 3, 4, 0]</td>\n","      <td>Tensor(\"Const_2:0\", shape=(1, 64, 1024), dtype...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Sentence: 100</td>\n","      <td>করে বাদ্যযন্ত্রের থিম এবং চলচ্চিত্রের জন্য প্র...</td>\n","      <td>[5, 0, 0, 0, 0, 0, 0, 0]</td>\n","      <td>Tensor(\"Const_3:0\", shape=(1, 64, 1024), dtype...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Sentence: 1000</td>\n","      <td>প্রতিষ্ঠান ২২১১ ইঙ্গিত করে যে আউগুস্তুস পৃথক ক...</td>\n","      <td>[0, 0, 0, 0, 0, 9, 0, 0, 0, 0, 0, 0, 0, 0]</td>\n","      <td>Tensor(\"Const_4:0\", shape=(1, 64, 1024), dtype...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Sentence: 10000</td>\n","      <td>শো স্টপারে তাদের বেকড আলাস্কা করতে সাড়ে চার ঘ...</td>\n","      <td>[0, 0, 0, 11, 12, 0, 0, 0, 0, 0, 0]</td>\n","      <td>Tensor(\"Const_5:0\", shape=(1, 64, 1024), dtype...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7390f383-da12-4114-a691-31288998ba70')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-7390f383-da12-4114-a691-31288998ba70 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-7390f383-da12-4114-a691-31288998ba70');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":[],"metadata":{"id":"G_Alki4z8hsx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["type(tf.convert_to_tensor(word_encoder(\"২০১৮ এর সেরা বর্ণানুক্রমিকভাবে\")))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dgP4Ri8x1zFP","executionInfo":{"status":"ok","timestamp":1680455685986,"user_tz":-360,"elapsed":2208,"user":{"displayName":"Niloy Farhan","userId":"08849852492544460038"}},"outputId":"ff714316-d629-4ad3-aeef-d601606cd713"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["tensorflow.python.framework.ops.Tensor"]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["df['word_encoded'][0].shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9bccl6wM-BlD","executionInfo":{"status":"ok","timestamp":1680455800975,"user_tz":-360,"elapsed":5,"user":{"displayName":"Niloy Farhan","userId":"08849852492544460038"}},"outputId":"3cf61dd2-c3a6-4782-d879-6ffe3093b4c0"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["TensorShape([1, 64, 1024])"]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["import numpy as np\n","x = df['word_encoded'].values.reshape(-1, 64, 1024)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":182},"id":"B6c5nNw9-2oE","executionInfo":{"status":"error","timestamp":1680455996706,"user_tz":-360,"elapsed":12,"user":{"displayName":"Niloy Farhan","userId":"08849852492544460038"}},"outputId":"08a3a8cc-40ca-4ec2-dd42-06af86d659dd"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-1611fba47bdc>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word_encoded'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 10 into shape (64,1024)"]}]},{"cell_type":"code","source":["import torch\n","import tensorflow as tf\n","\n","# define a simple TensorFlow model\n","modelT = tf.keras.Sequential([\n","    tf.keras.layers.Dense(1024, activation='relu', input_shape=(64,1024)),\n","    tf.keras.layers.Dense(256),\n","    tf.keras.layers.Dense(13)\n","])\n","METRICS = [\n","      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n","      tf.keras.metrics.Precision(name='precision'),\n","      tf.keras.metrics.Recall(name='recall')\n","]\n","\n","modelT.compile(optimizer='adam',\n","              loss='binary_crossentropy',\n","              metrics=METRICS)\n","# pass the TensorFlow tensor to the model\n","modelT.fit(x = df['word_encoded'], y = df['Tag'], epochs = 5)\n","\n","# print the output of the model"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":397},"id":"y5cOPNy5TVwD","executionInfo":{"status":"error","timestamp":1680456135943,"user_tz":-360,"elapsed":696,"user":{"displayName":"Niloy Farhan","userId":"08849852492544460038"}},"outputId":"96e0fd4c-7911-4b8b-f488-3763c3d24210"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-30-8cae1267b568>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m               metrics=METRICS)\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# pass the TensorFlow tensor to the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mmodelT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'word_encoded'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Tag'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# print the output of the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    854\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    855\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_select_training_loop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 856\u001b[0;31m         return func.fit(\n\u001b[0m\u001b[1;32m    857\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    696\u001b[0m         )\n\u001b[1;32m    697\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 698\u001b[0;31m         x, y, sample_weights = model._standardize_user_data(\n\u001b[0m\u001b[1;32m    699\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, batch_size, check_steps, steps_name, steps, validation_split, shuffle, extract_tensors_from_dataset)\u001b[0m\n\u001b[1;32m   2650\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2651\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2652\u001b[0;31m         return self._standardize_tensors(\n\u001b[0m\u001b[1;32m   2653\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2654\u001b[0m             \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36m_standardize_tensors\u001b[0;34m(self, x, y, sample_weight, run_eagerly, dict_inputs, is_dataset, class_weight, batch_size)\u001b[0m\n\u001b[1;32m   2691\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2692\u001b[0m             \u001b[0;31m# TODO(fchollet): run static checks with dataset output shape(s).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2693\u001b[0;31m             x = training_utils_v1.standardize_input_data(\n\u001b[0m\u001b[1;32m   2694\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2695\u001b[0m                 \u001b[0mfeed_input_names\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training_utils_v1.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    710\u001b[0m                 \u001b[0mshape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mshapes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    711\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_shape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 712\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    713\u001b[0m                         \u001b[0;34m\"Error when checking \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    714\u001b[0m                         \u001b[0;34m+\u001b[0m \u001b[0mexception_prefix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Error when checking input: expected dense_9_input to have 3 dimensions, but got array with shape (10, 1)"]}]},{"cell_type":"code","source":["import numpy as np"],"metadata":{"id":"MfWXfIGMZRYS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["tf.argmax(y_tf[0], axis = 1)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"T9irhlQMWtMl","executionInfo":{"status":"ok","timestamp":1680446955050,"user_tz":-360,"elapsed":3,"user":{"displayName":"Niloy Farhan","userId":"08849852492544460038"}},"outputId":"6ea9d122-7b5b-4d68-ad4d-17e0e14e2d62"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(6,), dtype=int64, numpy=array([8, 8, 8, 8, 8, 8])>"]},"metadata":{},"execution_count":84}]},{"cell_type":"code","source":[],"metadata":{"id":"G7SbXJRbZL-M"},"execution_count":null,"outputs":[]}]}