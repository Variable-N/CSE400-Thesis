{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5qJ_bf5Mb5_C","executionInfo":{"status":"ok","timestamp":1673006544162,"user_tz":-360,"elapsed":8232,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"8616b73f-fc7c-47c3-a59b-205f9709eaa0"},"outputs":[{"output_type":"stream","name":"stdout","text":["Hello\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting datasets\n","  Downloading datasets-2.8.0-py3-none-any.whl (452 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m452.9/452.9 KB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from datasets) (21.3)\n","Requirement already satisfied: pyarrow>=6.0.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (9.0.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.8/dist-packages (from datasets) (3.8.3)\n","Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (2022.11.0)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (4.64.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.8/dist-packages (from datasets) (1.3.5)\n","Collecting xxhash\n","  Downloading xxhash-3.2.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (213 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.0/213.0 KB\u001b[0m \u001b[31m23.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.8/dist-packages (from datasets) (1.21.6)\n","Requirement already satisfied: dill<0.3.7 in /usr/local/lib/python3.8/dist-packages (from datasets) (0.3.6)\n","Collecting huggingface-hub<1.0.0,>=0.2.0\n","  Downloading huggingface_hub-0.11.1-py3-none-any.whl (182 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.4/182.4 KB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting responses<0.19\n","  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n","Collecting multiprocess\n","  Downloading multiprocess-0.70.14-py38-none-any.whl (132 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m132.0/132.0 KB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.8/dist-packages (from datasets) (2.25.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.8/dist-packages (from datasets) (6.0)\n","Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (2.1.1)\n","Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.8.2)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.1)\n","Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (4.0.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (22.2.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (1.3.3)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.8/dist-packages (from aiohttp->datasets) (6.0.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.8.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->datasets) (3.0.9)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n","Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (4.0.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.19.0->datasets) (2022.12.7)\n","Collecting urllib3<1.27,>=1.21.1\n","  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m140.6/140.6 KB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2022.7)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n","Installing collected packages: xxhash, urllib3, multiprocess, responses, huggingface-hub, datasets\n","  Attempting uninstall: urllib3\n","    Found existing installation: urllib3 1.24.3\n","    Uninstalling urllib3-1.24.3:\n","      Successfully uninstalled urllib3-1.24.3\n","Successfully installed datasets-2.8.0 huggingface-hub-0.11.1 multiprocess-0.70.14 responses-0.18.0 urllib3-1.26.13 xxhash-3.2.0\n","--2023-01-06 12:02:22--  https://raw.githubusercontent.com/sighsmile/conlleval/master/conlleval.py\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 7502 (7.3K) [text/plain]\n","Saving to: ‘conlleval.py’\n","\n","conlleval.py        100%[===================>]   7.33K  --.-KB/s    in 0s      \n","\n","2023-01-06 12:02:22 (46.9 MB/s) - ‘conlleval.py’ saved [7502/7502]\n","\n"]}],"source":["print(\"Hello\")\n","!pip3 install datasets\n","!wget https://raw.githubusercontent.com/sighsmile/conlleval/master/conlleval.py"]},{"cell_type":"markdown","source":["# Import Conllu"],"metadata":{"id":"FI5nk2Fzj8kj"}},{"cell_type":"code","source":["!pip install conllu"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qyF-_rd8kNJ9","executionInfo":{"status":"ok","timestamp":1673006445759,"user_tz":-360,"elapsed":4005,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"9c77d326-27f1-4cee-bd7f-c7e4057d0c34"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting conllu\n","  Downloading conllu-4.5.2-py2.py3-none-any.whl (16 kB)\n","Installing collected packages: conllu\n","Successfully installed conllu-4.5.2\n"]}]},{"cell_type":"code","source":["from datasets import load_dataset\n","from collections import Counter\n","from conlleval import evaluate\n","import conllu\n","import csv"],"metadata":{"id":"mOLku4pKcVdo"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Dataset Loading"],"metadata":{"id":"47Z8pC3lkex2"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"deDsbsgIhLuW","executionInfo":{"status":"ok","timestamp":1673006441760,"user_tz":-360,"elapsed":18732,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"5ea3a107-8a2b-4a0b-f311-07a704d580f9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["train_data = open('/content/drive/MyDrive/Bracu/THESIS/bn_train.conll', mode = 'r', encoding = 'utf-8')\n","dev_data = open('/content/drive/MyDrive/Bracu/THESIS/bn_dev.conll', mode = 'r', encoding = 'utf-8')\n","test_data = open('/content/drive/MyDrive/Bracu/THESIS/bn_test.conll', mode = 'r', encoding = 'utf-8')\n","# train_data = load_dataset(\"conll2003\")\n","type(train_data)\n"],"metadata":{"id":"E5qf4FO5kD-D","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1673006615167,"user_tz":-360,"elapsed":344,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"c841240c-8b96-4138-adbe-6197e0fc1124"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["_io.TextIOWrapper"]},"metadata":{},"execution_count":19}]},{"cell_type":"markdown","source":["read string() return kore"],"metadata":{"id":"TBxdbQVwnF_E"}},{"cell_type":"code","source":["annotations = train_data.read()\n","print(annotations[:1000])"],"metadata":{"id":"PDFVjTANlN7o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["annotations = test_data.read()"],"metadata":{"id":"luhnrbI1xzAY"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def conll_to_dict(read):\n","    lines = read.split('\\n')\n","    count= 1\n","    outputList = {}\n","    for line in lines:\n","        if line.startswith('#'):  #ID\n","            word = []\n","            tag = []\n","            continue\n","        if line == '':  #Sentence End\n","            outputList[count] = [word, tag]\n","            count += 1\n","            continue\n","        line = line.split(' ')\n","        word.append(line[0])\n","        tag.append(line[-1])\n","    return outputList\n","x = conll_to_dict(annotations)\n","def dict_to_csv(x):\n","    with open('testData2022.csv', 'w', newline='', encoding= 'utf-8') as file:\n","        writer = csv.writer(file)\n","        writer.writerow([\"Sentence #\", \"Word\", \"Tag\"])\n","        for key, value in x.items():\n","            for i in range(len(value[0])):\n","                if i == 0:\n","                    writer.writerow([\"Sentence: \"+str(key), value[0][i], value[1][i]])\n","                else:\n","                    writer.writerow([None, value[0][i], value[1][i]])\n","\n","x = dict_to_csv(x)\n"],"metadata":{"id":"D74LA--2xy-V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"z51utA8zxy8M"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"5Bd8Rj_vxy6J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"1AxLRs6exy39"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lloGjdP1xy13"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"k7itlKOnxyzc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["parse() korle tokenize hoy in sentence"],"metadata":{"id":"lmW3kxLpnMig"}},{"cell_type":"code","source":["def get_dataset(path):\n","    with open(path) as f:\n","        dumb = ''\n","        count = 0\n","        tokens = []\n","        ner_tags = []\n","        token = []\n","        ner_tag = []\n","        for line in f: \n","            if line.strip('\\n') == '':\n","                tokens.append(token)\n","                ner_tags.append(ner_tag)\n","                token = []\n","                ner_tag=[]\n","                continue\n","            t = line.strip('\\n').split()[0]\n","            l = line.strip('\\n').split()[-1]\n","            if count < 5:\n","              dumb += str(t) +\"     \"+ (str(l)) + \"\\n\"\n","              count += 1\n","            token.append(t)\n","            ner_tag.append(l)\n","    print(len(tokens), len(ner_tags))\n","    print(tokens[0], ner_tags[0])\n","    print(dumb)\n","\n","    return {\n","        'tokens':tokens,\n","        'ner_tags':ner_tags\n","    }\n","\n","raw_train_data = get_dataset('')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Ad728SETV5_W","executionInfo":{"status":"ok","timestamp":1666201766737,"user_tz":-360,"elapsed":1045,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"74cf17c7-bd56-473b-9639-cf5c775958c9"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["15300 15300\n","['#', '২০১৮', 'এর', 'সেরা', '(বর্ণানুক্রমিকভাবে', 'তালিকাভুক্ত,', 'র\\u200d্যাঙ্ক', 'করা', 'হয়নি),', 'এনপিআর'] ['domain=train', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-CORP']\n","#     domain=train\n","২০১৮     O\n","এর     O\n","সেরা     O\n","(বর্ণানুক্রমিকভাবে     O\n","\n"]}]},{"cell_type":"code","source":["i = 0\n","x = \"\"\n","for key in raw_train_data: \n","  i+= 1\n","  if i == 10:\n","    break\n","  x += key + \"  \" + str(raw_train_data[key]) + '\\n'\n","\n","print(x[:1000])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"AuPH5ft2X71p","executionInfo":{"status":"ok","timestamp":1666202372453,"user_tz":-360,"elapsed":4,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"73887364-6e5b-4d40-85ba-dda3bf49ba1d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tokens  [['#', '২০১৮', 'এর', 'সেরা', '(বর্ণানুক্রমিকভাবে', 'তালিকাভুক্ত,', 'র\\u200d্যাঙ্ক', 'করা', 'হয়নি),', 'এনপিআর'], ['#', '১৮২৫', 'সালে,', 'তিনি', 'বোটানিক্যাল', 'গার্ডেনের', 'কিউরেটর', 'হয়েছিলেন', 'হার্ভার্ড', 'বিশ্ববিদ্যালয়', '।'], ['#', 'তিনি', 'মার্কো', 'মারুলি', 'লেখকের', 'সহযোগী', 'ছিলেন', 'বলেও', 'জানা', 'যায়।'], ['#', 'যে', 'দলটি', 'পরবর্তীতে', 'এমজি', 'মোটর', 'থেকে', 'প্রস্তুতকারকের', 'সহায়তা', 'গ্রহণ', 'করে,', '২০১', '২০১৮', 'সালে', 'ট্রেডিং', 'বন্ধ', 'করে', 'দেয়।'], ['#', 'এস্টেটে', 'দুটি', 'ঘর', 'এবং', 'একটি', 'উদ্ভিদ', 'উদ্যান', 'রয়েছে।'], ['#', '১৯৬১', 'সালে,', 'তিনি', 'এডলফ', 'আইখম্যান', 'এর', 'বিচারে', 'সাক্ষ্য', 'দেন।'], ['#', 'এটি', 'জিয়ান', 'লুইগি', 'রন্ডি', 'পরিচালিত', 'শেষ', 'সংস্করণ', 'ছিল।'], ['#', 'এটি', '১৯৩৮', 'সালে', 'স্টিফান', 'ভন', 'ব্রুনিং', 'দ্বারা', 'বর্ণনা', 'করা', 'হয়েছিল।'], ['#', 'স্টেশনটি', '১৯৮৫', 'সালের', 'মুভি', 'স্বর্গীয়', 'শিশু', 'এ', 'প্রদর্শিত', 'হয়েছিল।'], ['#', 'সিনেমায়', 'গানটির', 'বৈশিষ্ট্য', 'রয়েছে', 'রাস্তা', 'যাত্রা', \n"]}]},{"cell_type":"code","source":["sentences = conllu.parse(annotations)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":311},"id":"GHo2Wk_AlWaA","executionInfo":{"status":"error","timestamp":1666200808899,"user_tz":-360,"elapsed":24,"user":{"displayName":"NILOY FARHAN","userId":"17480483962253324951"}},"outputId":"8c3b6433-2582-4aaa-9c8b-3af7273aed65"},"execution_count":null,"outputs":[{"output_type":"error","ename":"ParseException","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mParseException\u001b[0m                            Traceback (most recent call last)","\u001b[0;32m<ipython-input-6-e88d64363023>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconllu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mannotations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/conllu/__init__.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(data, fields, field_parsers, metadata_parsers)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mfields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mfield_parsers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfield_parsers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mmetadata_parsers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata_parsers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     ))\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/conllu/models.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, sentences, metadata)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__next__\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m             \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/conllu/__init__.py\u001b[0m in \u001b[0;36mgenerator\u001b[0;34m()\u001b[0m\n\u001b[1;32m     41\u001b[0m                 \u001b[0mfields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                 \u001b[0mfield_parsers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfield_parsers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m                 \u001b[0mmetadata_parsers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadata_parsers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             )\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/conllu/parser.py\u001b[0m in \u001b[0;36mparse_token_and_metadata\u001b[0;34m(data, fields, field_parsers, metadata_parsers)\u001b[0m\n\u001b[1;32m     94\u001b[0m                 \u001b[0mmetadata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m             \u001b[0mtokens\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparse_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfields\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfield_parsers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mTokenList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdefault_fields\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfields\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/conllu/parser.py\u001b[0m in \u001b[0;36mparse_line\u001b[0;34m(line, fields, field_parsers)\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline_split\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mParseException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid line format, line must contain either tabs or two spaces.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mToken\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mParseException\u001b[0m: Invalid line format, line must contain either tabs or two spaces."]}]},{"cell_type":"code","source":["from io import open\n","from conllu import parse_incr\n","\n","for tokenlist in parse_incr(train_data):\n","    print(tokenlist)"],"metadata":{"id":"3Xwb72n8nfV2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"lLLSrmEAsv-q"},"execution_count":null,"outputs":[]}]}